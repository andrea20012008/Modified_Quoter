{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27997,"status":"ok","timestamp":1670744245273,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"N7EyPuqydrUE","outputId":"eecbac87-6cf5-48c0-dc07-ca0e21b6c034"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19707,"status":"ok","timestamp":1670744264971,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"0tGUB7jCfNrG","outputId":"55d0117e-d479-49d1-c1d6-bc4b093baf8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 30.8 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 71.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 41.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6b96ef158919aeed305f0b78c1911bf6a2a5470c6e79ba4844b60bb517e11f3c\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting OpenHowNet==0.0.1a11\n","  Downloading OpenHowNet-0.0.1a11-py3-none-any.whl (18 kB)\n","Collecting anytree\n","  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 765 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (4.64.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from anytree->OpenHowNet==0.0.1a11) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (1.24.3)\n","Installing collected packages: anytree, OpenHowNet\n","Successfully installed OpenHowNet-0.0.1a11 anytree-2.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.5\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 34.3 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (4.64.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434691 sha256=d3c24ab2042c6b23ebb4978db78305642b2ff02efef839bb7c54a162fc843036\n","  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed nltk-3.5\n"]}],"source":["!pip install transformers==3.0.2\n","!pip install OpenHowNet==0.0.1a11\n","!pip install nltk==3.5\n","#import transformers1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sb8bfoRhfQzc"},"outputs":[],"source":["import torch\n","from transformers import BertTokenizer, BertModel, AdamW, BertSememeModel\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import os\n","import time\n","import random\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import tqdm.notebook as tq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APW9_8Bdd4by"},"outputs":[],"source":["random.seed(42)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch = 2\n","sample_num = 19\n","learning_rate = 3e-5\n","epochs = 40\n","max_length = 80"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tDLcHlLd8yf"},"outputs":[],"source":["def load_data(path):\n","    with open(path, 'r', encoding='utf-8') as f:\n","        former, middle, latter = [], [], []\n","\n","        lines = f.readlines()\n","        for line in lines:\n","            line = line.strip().lower().split('\\t')\n","            former.append(line[0])\n","            middle.append(line[1])\n","            latter.append(line[2])\n","        \n","        train_former, valid_former, test_former = former[:1000], former[1000:2000], former[2000:3000]\n","        train_middle, valid_middle, test_middle = middle[:1000], middle[1000:2000], middle[2000:3000]\n","        train_latter, valid_latter, test_latter = latter[:1000], latter[1000:2000], latter[2000:3000]\n","\n","    all_quotes = train_middle + valid_middle + test_middle\n","    all_quotes = sorted(list(set(all_quotes)))\n","\n","    y_train = [all_quotes.index(q) for q in train_middle]\n","    y_valid = [all_quotes.index(q) for q in valid_middle]\n","    y_test = [all_quotes.index(q) for q in test_middle]\n","\n","    trains = [train_former, train_middle, train_latter]\n","    valids = [valid_former, valid_middle, valid_latter]\n","    tests = [test_former, test_middle, test_latter]\n","    y = [torch.LongTensor(y_train), torch.LongTensor(y_valid), torch.LongTensor(y_test)]\n","\n","    return trains, valids, tests, y , all_quotes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7aa7bdc5d41a4e4dbb77e2a43f2f5c5e","a01ca734b0ed42a0996d0ef8c7e2ef79","fca2ccca9985409c8279bdf4bf349811","f5e646c077d94642a8038a08413b3778","ffdf1c0a9f744481a47124e8ec69b540","1785a34d4f4f4b55b046f06d7ebd01bc","b8506608c95e42e89601c8eb3614cc92","fcdf0b2294c14caab5d6f169b04deeca","8466b06d82864531b2c6cf31940b07fe","7bb16e88c15b4b16a7c6c7ba8f931391","640beb53c7384b659b0a9f14a1b8b15c"]},"executionInfo":{"elapsed":3606,"status":"ok","timestamp":1670744497509,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"Z2ngFzPXeARp","outputId":"32e9c3de-37bd-4769-d7bc-21bcd4528c4f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7aa7bdc5d41a4e4dbb77e2a43f2f5c5e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/110k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["data_path = \"/content/drive/MyDrive/quoter/data/ancient_chinese.txt\"\n","trains, valids, tests, y, all_quotes = load_data(data_path)\n","\n","# get the Tokenizer used for pretraining model\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlUMs3IkeF_n"},"outputs":[],"source":["# Obtained directly from the source code\n","def make_context_tensors(former, latter):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","    mask_ids = []\n","    for f, l in zip(former, latter):\n","        sent = f + \"[MASK]\" + l\n","        encoded_dict = tokenizer.encode_plus(sent,\n","                                             add_special_tokens=True,\n","                                             max_length=150,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict['token_type_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        mask_index = encoded_dict['input_ids'][0].tolist().index(103)\n","        mask_ids.append(mask_index)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    return input_ids, token_type_ids, attention_masks, torch.LongTensor(mask_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QZu_QMRJBYu"},"outputs":[],"source":["train_input_ids, train_token_type_ids, train_attention_masks, train_mask_ids = make_context_tensors(trains[0], trains[2])\n","valid_input_ids, valid_token_type_ids, valid_attention_masks, valid_mask_ids = make_context_tensors(valids[0], valids[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNt4kqlWeOWJ"},"outputs":[],"source":["# Obtained directly from source code\n","class Dataset(Dataset):\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 quote):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.quote = quote\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.quote is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.quote[\n","                idx]\n","\n","\n","train_dataset = Dataset(input_ids=train_input_ids,\n","                        token_type_ids=train_token_type_ids,\n","                        attention_masks=train_attention_masks,\n","                        mask_ids=train_mask_ids,\n","                        quote=trains[1])\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n","valid_dataset = Dataset(input_ids=valid_input_ids,\n","                        token_type_ids=valid_token_type_ids,\n","                        attention_masks=valid_attention_masks,\n","                        mask_ids=valid_mask_ids,\n","                        quote=valids[1])\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSQOsfcSTM9P"},"outputs":[],"source":["def generate_quotes(quote, num):\n","    quotes_selcet = all_quotes[:]\n","    quotes_selcet.remove(quote)\n","    quotes = random.sample(quotes_selcet, num)\n","    quotes.append(quote)\n","    random.shuffle(quotes)\n","    return quotes\n","\n","# Obtained directly from the source code\n","def make_quote_tensors(quote):\n","    quotes = generate_quotes(quote, num=sample_num)\n","    label = quotes.index(quote)\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)  # [num, 80]\n","    quote_ids = torch.LongTensor([all_quotes.index(q) for q in quotes])\n","    return input_ids, label, quote_ids\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6610,"status":"ok","timestamp":1670744772945,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"GYFi7GbKeWsN","outputId":"8a348fb8-ac24-40db-fe3f-a30b5b9d595f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:transformers.modeling_utils:Some weights of BertSememeModel were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['bert.embeddings.sememe_embeddings.lut.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["QuotRec_Net(\n","  (context_model): Context_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (quote_model): Quote_Encoder(\n","    (bert_model): BertSememeModel(\n","      (embeddings): BertSememeEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (sememe_embeddings): SememeEmbeddings(\n","          (lut): Embedding(2187, 768)\n","        )\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["class Context_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, context_input_ids, context_token_type_ids, context_attention_masks, mask_ids):\n","        outputs = self.bert_model(input_ids=context_input_ids,\n","                                  token_type_ids=context_token_type_ids,\n","                                  attention_mask=context_attention_masks)\n","        \n","        last_hidden_state = outputs[0]\n","        all_context = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            mask = self.dropout(mask)\n","            context = mask.unsqueeze(dim=0)\n","            all_context.append(context)\n","\n","        return torch.cat(all_context, dim=0)\n","\n","\n","class Quote_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertSememeModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        # self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, quotes):\n","        quote_tensor = []\n","        labels = []\n","        for quote in quotes:\n","            quote_input_ids, label, quote_ids = make_quote_tensors(quote)\n","            quote_input_ids = quote_input_ids.to(device)\n","            quote_ids = quote_ids.to(device)\n","            outputs = self.bert_model(input_ids=quote_input_ids)\n","            output = torch.mean(outputs[0], dim=1)\n","            \n","            quote_tensor.append(output)\n","            labels.append(label)\n","        quote_tensor = torch.stack(quote_tensor, dim=0)\n","        return quote_tensor, labels\n","\n","\n","class QuotRec_Net(nn.Module):\n","    def __init__(self, context_model, quote_model):\n","        super().__init__()\n","        self.context_model = context_model\n","        self.quote_model = quote_model\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                quotes):\n","        context_output = self.context_model(input_ids, token_type_ids,\n","                                           attention_masks, mask_ids)\n","        context_output = context_output.unsqueeze(dim=1)\n","\n","        quote_output, labels = self.quote_model(quotes)\n","        quote_output = quote_output.permute(0, 2, 1)\n","\n","        outputs = torch.matmul(context_output, quote_output).squeeze(dim=1)\n","        return outputs, torch.LongTensor(labels)\n","\n","context_model = Context_Encoder()\n","quote_model = Quote_Encoder()\n","model = QuotRec_Net(context_model, quote_model)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":245,"referenced_widgets":["da7884ef468a413289fcfb87d8dbdcec","7944b3fe77d24aabb69b44fbfd2ab218","e82eeb760bfe4727a93bbdedd69c0892","71b04d983ea5423596ff0911c4ea314e","1efac5b88dbb4b9f82685bef7f68685d","c1f52ae80e364d9bb2bec53e07cc830f","a4c04145be4545cf9c06d10ab3b382c6","2c4f006138b94bfab761644d04fa7c0d","63da9f762ce843dca5f220241c516924","21d94fb68724420088d6416f262ce7e3","4e4602dc7e594e149a44e26796927bbe"]},"id":"mlczWb0UeeQ2","outputId":"77f1051f-c379-4378-e5d7-e2afeec4289b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da7884ef468a413289fcfb87d8dbdcec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch:  1\n","Train | Loss:1550.71094 Acc:0.154\n","Valid | Loss:1201.62271 Acc:0.274\n","Epoch:  2\n","Train | Loss:1414.22449 Acc:0.191\n","Valid | Loss:1497.86766 Acc:0.041\n","Epoch:  3\n","Train | Loss:1568.87290 Acc:0.066\n","Valid | Loss:1497.86828 Acc:0.037\n","Epoch:  4\n","Train | Loss:1564.11666 Acc:0.046\n","Valid | Loss:1497.86899 Acc:0.036\n","Early Stopping\n"]}],"source":["import math\n","def training(model, epoch, train, valid, device):\n","\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_acc = 0\n","    best_loss = math.inf\n","    losses = []\n","    count = 0\n","\n","    for epoch in tq.tqdm(range(epoch)):\n","        start = time.perf_counter()\n","        total_loss, total_acc = 0, 0\n","        print(\"Epoch: \", epoch + 1)\n","\n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs, labels = model(input_ids, token_type_ids, attention_masks,mask_ids, quotes)\n","            labels = labels.to(device, dtype=torch.long)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, pred = torch.max(outputs.cpu().data, 1)\n","            acc = accuracy_score(pred, labels.cpu())\n","            total_loss += loss.item()\n","            total_acc += acc\n","        print('Train | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_train))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","\n","                outputs, labels = model(input_ids, token_type_ids,attention_masks, mask_ids, quotes)\n","                labels = labels.to(device, dtype=torch.long)\n","                loss = criterion(outputs, labels)\n","                _, pred = torch.max(outputs.cpu().data, 1)\n","\n","                acc = accuracy_score(pred, labels.cpu())\n","                total_loss += loss.item()\n","                total_acc += acc\n","            losses.append(total_loss)\n","            print('Valid | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_valid))\n","\n","            if total_acc >= best_acc and total_loss <= best_loss:\n","                best_acc = total_acc\n","                best_loss = total_loss\n","                if not os.path.exists(\"./model\"):\n","                    os.mkdir(\"./model\")\n","                torch.save(model.quote_model.state_dict(), \"/content/drive/MyDrive/model/ancient_chinese_quote.pth\")\n","                torch.save(model.context_model.state_dict(), \"/content/drive/MyDrive/model/ancient_chinese_context.pth\")\n","                count = 0\n","            elif total_loss > best_loss:\n","                count += 1\n","\n","        end = time.perf_counter()\n","\n","        if count == 3:\n","            print(\"Early Stopping\")\n","            break\n","\n","\n","training(model=model,\n","         epoch=epochs,\n","         train=train_loader,\n","         valid=valid_loader,\n","         device=device)\n","\n","\n","def make_tensors(quotes):\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)\n","    return input_ids\n","\n","\n","quote_input_ids = make_tensors(all_quotes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BgODzAlUelT-"},"outputs":[],"source":["# Generate sentence vector for quotes\n","quote_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","model_dict = quote_model.state_dict()\n","save_model_state = torch.load(\"/content/drive/MyDrive/model/ancient_chinese_quote.pth\")\n","\n","state_dict = {k[11:]: v for k, v in save_model_state.items() if k[11:] in model_dict.keys()}\n","model_dict.update(state_dict)\n","quote_model.load_state_dict(model_dict)\n","\n","quote_model = quote_model.to(device)\n","quote_input_ids = quote_input_ids.to(device)\n","\n","quote_embeddings = []\n","quote_model.eval()\n","\n","with torch.no_grad():\n","    for input_ids in quote_input_ids:\n","        input_ids = input_ids.unsqueeze(dim=0)\n","        outputs = quote_model(input_ids=input_ids)\n","        quote_tensor = torch.mean(outputs[0], dim=1)\n","        quote_embeddings.append(quote_tensor)\n","    quote_embeddings = torch.cat(quote_embeddings, dim=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P82Gpy9MTjVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670747188891,"user_tz":-540,"elapsed":2843,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"2bdf20f9-8540-4cb1-9091-c298b1177db2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRecNet(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":20}],"source":["# Use the mask method for training\n","class QuotRecNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks,\n","                mask_ids, quote_tensor):\n","        outputs = self.bert_model(input_ids=input_ids,\n","                                  token_type_ids=token_type_ids,\n","                                  attention_mask=attention_masks)\n","        last_hidden_state = outputs[0]\n","        all_outputs = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            context = self.dropout(mask)\n","            context = context.unsqueeze(dim=0)\n","            output = torch.mm(context, quote_tensor.t())\n","            all_outputs.append(output)\n","        all_outputs = torch.cat(all_outputs, dim=0)\n","        return all_outputs\n","\n","\n","model = QuotRecNet()\n","model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OvvDjTWe0ke"},"outputs":[],"source":["# Evaluation Metrics\n","# Rank\n","def rank_gold(predicts, golds):\n","  ranks = []\n","  ps = predicts.data.cpu().numpy()\n","  gs = golds.cpu().numpy()\n","  for i in range(len(ps)):\n","    predict = ps[i]\n","    gold_index = gs[i]\n","    predict_value = predict[gold_index]\n","    predict_sort = sorted(predict, reverse=True)\n","    predict_index = predict_sort.index(predict_value)\n","    if predict_index == -1:\n","        break\n","    ranks.append(predict_index)\n","  return ranks\n","\n","\n","# NDCG@5\n","def get_NDCG(ranks):\n","    total = 0.0\n","    for r in ranks:\n","        if r < 5:  # k=5\n","            total += 1.0 / np.log2(r + 2)\n","    return total / len(ranks)\n","\n","\n","# get recall@k\n","def recall(predicts, golds):\n","    predicts = predicts.data.cpu().numpy()\n","    golds = list(golds)\n","    predicts_index = list(np.argsort(-predicts, axis=1))\n","    predicts_index = [list(element) for element in predicts_index]\n","    recall_values = [0, 0, 0, 0, 0, 0, 0] # 1, 3, 5, 10, 20, 30, 100, 300, 500\n","    recalls = [1, 3, 5, 10, 20, 30, 100]\n","\n","    for i in range(len(golds)):\n","        gold_value_index = predicts_index[i].index(golds[i])\n","        for val in range(len(recalls)):\n","            if gold_value_index < recalls[val]:\n","                recall_values[val] += 1\n","\n","    return recall_values\n","\n","def get_mrr(ranks):\n","    return np.average([1.0 / (r + 1) for r in ranks])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndwGb997fFVD"},"outputs":[],"source":["def training_mask(model, epoch, train, valid, quote_tensor, device):\n","    learning_rate = 3e-5\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_MRR = 0\n","    count = 0\n","    quote_tensor = quote_tensor.to(device)\n","    for epoch in range(epoch):\n","        start = time.perf_counter()\n","        print(\"Epoch: \", epoch + 1)\n","        total_loss, total_MRR, total_NDCG = 0, 0, 0\n","        \n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","  \n","            ranks = rank_gold(outputs, labels)\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","        end = time.perf_counter()\n","        print('Epoch running time :{:.0f}'.format(end - start))\n","        print('Train | Loss:{:.3f} MRR: {:.3f} NDCG: {:.3f}'.format(total_loss, total_MRR/len_train, total_NDCG/len_train))\n","\n","        # validation\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_MRR, total_NDCG = 0, 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.long)\n","                outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","                loss = criterion(outputs, labels)\n","                \n","                ranks = rank_gold(outputs, labels)\n","                MRR = get_mrr(ranks)\n","                NDCG = get_NDCG(ranks)\n","                \n","                total_loss += loss.item()\n","                total_MRR += MRR\n","                total_NDCG += NDCG\n","            print(\"Valid | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f}\".format(total_loss, total_MRR / len_valid,total_NDCG / len_valid))\n","        \n","        if total_MRR > best_MRR:\n","            best_MRR = total_MRR\n","            torch.save(model, \"/content/drive/MyDrive/model/model_ancient_chinese.model\")\n","            count = 0\n","        else:\n","            learning_rate = learning_rate * 0.9\n","            count += 1\n","        \n","        # Early Stopping\n","        if count == 3:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":999535,"status":"ok","timestamp":1670748260802,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"EMMwKZXYe5mG","outputId":"26d77bad-8b34-4b0c-9c84-80fe4de2f9b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading train and valid dataloader ...\n","start traing......\n","Epoch:  1\n","Epoch running time :44\n","Train | Loss:3152.588 MRR: 0.084 NDCG: 0.075\n","Valid | Loss:3257.29814 MRR: 0.061 NDCG: 0.053\n","Epoch:  2\n","Epoch running time :50\n","Train | Loss:2595.986 MRR: 0.209 NDCG: 0.207\n","Valid | Loss:3157.99882 MRR: 0.092 NDCG: 0.088\n","Epoch:  3\n","Epoch running time :46\n","Train | Loss:2063.913 MRR: 0.380 NDCG: 0.393\n","Valid | Loss:3130.02969 MRR: 0.099 NDCG: 0.092\n","Epoch:  4\n","Epoch running time :46\n","Train | Loss:1650.550 MRR: 0.572 NDCG: 0.593\n","Valid | Loss:3106.73895 MRR: 0.105 NDCG: 0.100\n","Epoch:  5\n","Epoch running time :47\n","Train | Loss:1334.009 MRR: 0.721 NDCG: 0.750\n","Valid | Loss:3091.30503 MRR: 0.119 NDCG: 0.116\n","Epoch:  6\n","Epoch running time :46\n","Train | Loss:1132.749 MRR: 0.814 NDCG: 0.842\n","Valid | Loss:3077.95901 MRR: 0.123 NDCG: 0.119\n","Epoch:  7\n","Epoch running time :46\n","Train | Loss:953.085 MRR: 0.883 NDCG: 0.901\n","Valid | Loss:3080.56259 MRR: 0.126 NDCG: 0.121\n","Epoch:  8\n","Epoch running time :46\n","Train | Loss:815.372 MRR: 0.926 NDCG: 0.940\n","Valid | Loss:3068.53981 MRR: 0.126 NDCG: 0.122\n","Epoch:  9\n","Epoch running time :47\n","Train | Loss:700.463 MRR: 0.956 NDCG: 0.966\n","Valid | Loss:3091.37649 MRR: 0.125 NDCG: 0.120\n","Epoch:  10\n","Epoch running time :46\n","Train | Loss:611.784 MRR: 0.971 NDCG: 0.978\n","Valid | Loss:3069.98351 MRR: 0.126 NDCG: 0.118\n","Epoch:  11\n","Epoch running time :46\n","Train | Loss:548.108 MRR: 0.980 NDCG: 0.985\n","Valid | Loss:3074.95620 MRR: 0.130 NDCG: 0.125\n","Epoch:  12\n","Epoch running time :46\n","Train | Loss:486.958 MRR: 0.987 NDCG: 0.990\n","Valid | Loss:3066.72848 MRR: 0.131 NDCG: 0.127\n","Epoch:  13\n","Epoch running time :47\n","Train | Loss:437.168 MRR: 0.988 NDCG: 0.991\n","Valid | Loss:3085.06426 MRR: 0.125 NDCG: 0.122\n","Epoch:  14\n","Epoch running time :46\n","Train | Loss:404.167 MRR: 0.991 NDCG: 0.993\n","Valid | Loss:3073.54068 MRR: 0.135 NDCG: 0.130\n","Epoch:  15\n","Epoch running time :46\n","Train | Loss:370.483 MRR: 0.994 NDCG: 0.996\n","Valid | Loss:3084.14345 MRR: 0.127 NDCG: 0.124\n","Epoch:  16\n","Epoch running time :46\n","Train | Loss:348.206 MRR: 0.995 NDCG: 0.996\n","Valid | Loss:3118.71379 MRR: 0.133 NDCG: 0.130\n","Epoch:  17\n","Epoch running time :46\n","Train | Loss:316.976 MRR: 0.996 NDCG: 0.997\n","Valid | Loss:3074.21985 MRR: 0.134 NDCG: 0.128\n"]}],"source":["# Mask Dataset and DataLoader\n","class Dataset_Mask(Dataset):\n","\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 y):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.label = y\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.label[\n","                idx]\n","\n","\n","print(\"loading train and valid dataloader ...\")\n","train_dataset_mask = Dataset_Mask(input_ids=train_input_ids,\n","                                  token_type_ids=train_token_type_ids,\n","                                  attention_masks=train_attention_masks,\n","                                  mask_ids=train_mask_ids,\n","                                  y=y[0])\n","train_loader_mask = DataLoader(dataset=train_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","valid_dataset_mask = Dataset_Mask(input_ids=valid_input_ids,\n","                                  token_type_ids=valid_token_type_ids,\n","                                  attention_masks=valid_attention_masks,\n","                                  mask_ids=valid_mask_ids,\n","                                  y=y[1])\n","valid_loader_mask = DataLoader(dataset=valid_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","print(\"start traing......\")\n","training_mask(model=model,\n","              epoch=epochs,\n","              train=train_loader_mask,\n","              valid=valid_loader_mask,\n","              quote_tensor=quote_embeddings,\n","              device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17125,"status":"ok","timestamp":1670748384300,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"},"user_tz":-540},"id":"w_WTyan4fBLJ","outputId":"bd16e540-9d3f-4a5e-d1a7-b21ad03b74a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test | Loss:3098.79040 MRR: 0.123 NDCG: 0.115 Mean Rank: 236 Median Rank: 98 Variance: 310\n","Recall@[1,3,5,10,20,30,100]: [0.078, 0.129, 0.148, 0.199, 0.274, 0.314, 0.504]\n"]}],"source":["def test(model, test_loader, quote_tensor, device):\n","    model.eval()\n","    t_batch = len(test_loader)\n","    criterion = nn.CrossEntropyLoss()\n","    quote_tensor = quote_tensor.to(device)\n","    with torch.no_grad():\n","        total_loss, total_MRR, total_NDCG, total_ranks = 0, 0, 0, 0\n","        total_recalls = [0, 0, 0, 0, 0, 0, 0]\n","        all_ranks = []\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            \n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            \n","            ranks = rank_gold(outputs, labels)\n","            all_ranks += ranks\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            recalls = recall(outputs, labels)\n","            \n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","            total_ranks += np.sum(ranks)\n","            total_recalls = [x + y for x, y in zip(total_recalls, recalls)]\n","\n","        total_recalls = [element / len(y[2]) for element in total_recalls]\n","\n","        print(\n","            \"Test | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f} Mean Rank: {:.0f} Median Rank: {:.0f} Variance: {:.0f}\"\n","            .format(total_loss, total_MRR / t_batch,\n","                    total_NDCG / t_batch, np.mean(all_ranks),\n","                    np.median(all_ranks)+1,\n","                    np.std(all_ranks)))\n","        print(\"Recall@[1,3,5,10,20,30,100]: \" + str(total_recalls))\n","        \n","\n","test_input_ids, test_token_type_ids, test_attention_masks, test_mask_ids = make_context_tensors(tests[0], tests[2])\n","test_dataset_mask = Dataset_Mask(input_ids=test_input_ids,\n","                                 token_type_ids=test_token_type_ids,\n","                                 attention_masks=test_attention_masks,\n","                                 mask_ids=test_mask_ids,\n","                                 y=y[2])\n","test_loader_mask = DataLoader(dataset=test_dataset_mask,\n","                              batch_size=batch,\n","                              num_workers=2)\n","\n","model = torch.load('/content/drive/MyDrive/model/model_ancient_chinese.model')\n","model.to(device)\n","test(model=model,\n","     test_loader=test_loader_mask,\n","     quote_tensor=quote_embeddings,\n","     device=device)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1785a34d4f4f4b55b046f06d7ebd01bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1efac5b88dbb4b9f82685bef7f68685d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d94fb68724420088d6416f262ce7e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4f006138b94bfab761644d04fa7c0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e4602dc7e594e149a44e26796927bbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63da9f762ce843dca5f220241c516924":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"640beb53c7384b659b0a9f14a1b8b15c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b04d983ea5423596ff0911c4ea314e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21d94fb68724420088d6416f262ce7e3","placeholder":"​","style":"IPY_MODEL_4e4602dc7e594e149a44e26796927bbe","value":" 3/40 [20:38&lt;4:14:40, 412.99s/it]"}},"7944b3fe77d24aabb69b44fbfd2ab218":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1f52ae80e364d9bb2bec53e07cc830f","placeholder":"​","style":"IPY_MODEL_a4c04145be4545cf9c06d10ab3b382c6","value":"  8%"}},"7aa7bdc5d41a4e4dbb77e2a43f2f5c5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a01ca734b0ed42a0996d0ef8c7e2ef79","IPY_MODEL_fca2ccca9985409c8279bdf4bf349811","IPY_MODEL_f5e646c077d94642a8038a08413b3778"],"layout":"IPY_MODEL_ffdf1c0a9f744481a47124e8ec69b540"}},"7bb16e88c15b4b16a7c6c7ba8f931391":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8466b06d82864531b2c6cf31940b07fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a01ca734b0ed42a0996d0ef8c7e2ef79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1785a34d4f4f4b55b046f06d7ebd01bc","placeholder":"​","style":"IPY_MODEL_b8506608c95e42e89601c8eb3614cc92","value":"Downloading: 100%"}},"a4c04145be4545cf9c06d10ab3b382c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8506608c95e42e89601c8eb3614cc92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1f52ae80e364d9bb2bec53e07cc830f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da7884ef468a413289fcfb87d8dbdcec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7944b3fe77d24aabb69b44fbfd2ab218","IPY_MODEL_e82eeb760bfe4727a93bbdedd69c0892","IPY_MODEL_71b04d983ea5423596ff0911c4ea314e"],"layout":"IPY_MODEL_1efac5b88dbb4b9f82685bef7f68685d"}},"e82eeb760bfe4727a93bbdedd69c0892":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4f006138b94bfab761644d04fa7c0d","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63da9f762ce843dca5f220241c516924","value":3}},"f5e646c077d94642a8038a08413b3778":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bb16e88c15b4b16a7c6c7ba8f931391","placeholder":"​","style":"IPY_MODEL_640beb53c7384b659b0a9f14a1b8b15c","value":" 110k/110k [00:00&lt;00:00, 189kB/s]"}},"fca2ccca9985409c8279bdf4bf349811":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcdf0b2294c14caab5d6f169b04deeca","max":109540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8466b06d82864531b2c6cf31940b07fe","value":109540}},"fcdf0b2294c14caab5d6f169b04deeca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffdf1c0a9f744481a47124e8ec69b540":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}