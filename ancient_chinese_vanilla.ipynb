{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"8dc6a6fcfe4049d89f08eaaf4e3c06c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_442cf7f5599740fca4b2a9742b8da90b","IPY_MODEL_2f030d14f91a42cbb0c4fdb9e268807a","IPY_MODEL_a2146538ab074343902a6146d2549c52"],"layout":"IPY_MODEL_39815848045b4f4f97ea1367a9dc6fdf"}},"442cf7f5599740fca4b2a9742b8da90b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6129d787f704956b859e54fe9f69f01","placeholder":"​","style":"IPY_MODEL_ac0ea0291aa34490bf42e8a04a19a279","value":"Downloading: 100%"}},"2f030d14f91a42cbb0c4fdb9e268807a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab0669fb50ce41578cfa014c12673a24","max":109540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66de55e46d924303a393aa79380ff2ad","value":109540}},"a2146538ab074343902a6146d2549c52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_178f525ec3054577b366438f0dfb3ae0","placeholder":"​","style":"IPY_MODEL_33ca0ae10de648c3b46427a41e4ed13d","value":" 110k/110k [00:00&lt;00:00, 493kB/s]"}},"39815848045b4f4f97ea1367a9dc6fdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6129d787f704956b859e54fe9f69f01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac0ea0291aa34490bf42e8a04a19a279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab0669fb50ce41578cfa014c12673a24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66de55e46d924303a393aa79380ff2ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"178f525ec3054577b366438f0dfb3ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ca0ae10de648c3b46427a41e4ed13d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a364bdc4d49544259e7e249c61f4e77a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_028a0373f019409db358c347e8834bd1","IPY_MODEL_d8b8036a6c5843e9ab98af552dc141fc","IPY_MODEL_9ef451ac08a4488eae5aec6ac24fcee7"],"layout":"IPY_MODEL_055e81de2b5c4d3ca04c1fa9ec8b4e28"}},"028a0373f019409db358c347e8834bd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc4cc2d869884e02a4d57f7839f95692","placeholder":"​","style":"IPY_MODEL_25f504cbbd2e4fdebe7247af0b7a1fd6","value":"Downloading: 100%"}},"d8b8036a6c5843e9ab98af552dc141fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad6005a57cb4e279d084525ca7ae13a","max":624,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9adf5d0e5e742dc884389ebdacd9dfa","value":624}},"9ef451ac08a4488eae5aec6ac24fcee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_120c361326074beaa50cea23c282efa7","placeholder":"​","style":"IPY_MODEL_283e685670484c12a7aba0dd8fa5118b","value":" 624/624 [00:00&lt;00:00, 18.3kB/s]"}},"055e81de2b5c4d3ca04c1fa9ec8b4e28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc4cc2d869884e02a4d57f7839f95692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f504cbbd2e4fdebe7247af0b7a1fd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad6005a57cb4e279d084525ca7ae13a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9adf5d0e5e742dc884389ebdacd9dfa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"120c361326074beaa50cea23c282efa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"283e685670484c12a7aba0dd8fa5118b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"101ef97a2251496ba60a9e0c3080b887":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32f551e725304be4bfe55d6014d3fb0b","IPY_MODEL_dc128b911b3b40f2b8787732974ebdd5","IPY_MODEL_a6b5c2a8ecab4dc6941ee6adbe1e75ee"],"layout":"IPY_MODEL_4c4392249da84aa1bbad5408880c2fc1"}},"32f551e725304be4bfe55d6014d3fb0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c94276c1bb94dadbe3d087e035ae3ca","placeholder":"​","style":"IPY_MODEL_d237e8834fb34560a95e681f29162175","value":"Downloading: 100%"}},"dc128b911b3b40f2b8787732974ebdd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_716ce13829dd48f7a9df1f9496acc553","max":411577189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e5c8aece889423682801f40f03c9ef0","value":411577189}},"a6b5c2a8ecab4dc6941ee6adbe1e75ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_789817810ea94ee5a4a321ee18c454dd","placeholder":"​","style":"IPY_MODEL_1e4c98cef11f482298fa4c8e472a3d31","value":" 412M/412M [00:06&lt;00:00, 72.9MB/s]"}},"4c4392249da84aa1bbad5408880c2fc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c94276c1bb94dadbe3d087e035ae3ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d237e8834fb34560a95e681f29162175":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"716ce13829dd48f7a9df1f9496acc553":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e5c8aece889423682801f40f03c9ef0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"789817810ea94ee5a4a321ee18c454dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4c98cef11f482298fa4c8e472a3d31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58023d0b6f644aebaf67bbfe0c4f8196":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63394b5705694887935aafa9a487d306","IPY_MODEL_d9cab0bbf1e2438dbdb8df490d4ce7f5","IPY_MODEL_3aaea614a0c846ee958493fe1910d17e"],"layout":"IPY_MODEL_58d0895df1454d6e84c4aa32d7c90112"}},"63394b5705694887935aafa9a487d306":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03f2744983404812a2215a005ce16b05","placeholder":"​","style":"IPY_MODEL_734fc72e22574d3194ff5e71c47a07e6","value":"  8%"}},"d9cab0bbf1e2438dbdb8df490d4ce7f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3498d89e0eb4ae3a5d34766f89b13c3","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3d370bdf13244d1a41ca59be3eb4113","value":3}},"3aaea614a0c846ee958493fe1910d17e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6caf7c944a9b43ee8ac24f831b9b81cb","placeholder":"​","style":"IPY_MODEL_89c6887e7f754ed7b81e3928134eb5b4","value":" 3/40 [27:29&lt;4:14:15, 412.32s/it]"}},"58d0895df1454d6e84c4aa32d7c90112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03f2744983404812a2215a005ce16b05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"734fc72e22574d3194ff5e71c47a07e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3498d89e0eb4ae3a5d34766f89b13c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3d370bdf13244d1a41ca59be3eb4113":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6caf7c944a9b43ee8ac24f831b9b81cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c6887e7f754ed7b81e3928134eb5b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7EyPuqydrUE","executionInfo":{"status":"ok","timestamp":1670743605720,"user_tz":-540,"elapsed":19859,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"19f05c7f-a5e9-414e-d2a7-d48c38f9bfda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers==3.0.2\n","!pip install OpenHowNet==0.0.1a11\n","!pip install nltk==3.5\n","#import transformers1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tGUB7jCfNrG","executionInfo":{"status":"ok","timestamp":1670743623448,"user_tz":-540,"elapsed":17736,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"d469c42e-b1f2-46cb-8a6b-26af4177a742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 65.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ab2353b080f26e9097247fb4e3296f7b5584c1e6658f67adcba4d78b43498107\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting OpenHowNet==0.0.1a11\n","  Downloading OpenHowNet-0.0.1a11-py3-none-any.whl (18 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (4.64.1)\n","Collecting anytree\n","  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 712 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.23.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from anytree->OpenHowNet==0.0.1a11) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (1.24.3)\n","Installing collected packages: anytree, OpenHowNet\n","Successfully installed OpenHowNet-0.0.1a11 anytree-2.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.5\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (4.64.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434691 sha256=bdc1db11f5da381f35094090efed0d2ae1c29bbd3fd79d212fdba4f75493aae3\n","  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed nltk-3.5\n"]}]},{"cell_type":"code","source":["import torch\n","import tqdm.notebook as tq\n","from transformers import BertTokenizer, BertModel, AdamW\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import os\n","import time\n","import random\n","from sklearn.metrics import accuracy_score\n","import numpy as np"],"metadata":{"id":"Sb8bfoRhfQzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(42)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch = 2\n","sample_num = 19\n","learning_rate = 3e-5\n","epochs = 40\n","max_length = 80"],"metadata":{"id":"APW9_8Bdd4by"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(path):\n","    with open(path, 'r', encoding='utf-8') as f:\n","        former, middle, latter = [], [], []\n","\n","        lines = f.readlines()\n","        for line in lines:\n","            line = line.strip().lower().split('\\t')\n","            former.append(line[0])\n","            middle.append(line[1])\n","            latter.append(line[2])\n","        \n","        train_former, valid_former, test_former = former[:1000], former[1000:2000], former[2000:3000]\n","        train_middle, valid_middle, test_middle = middle[:1000], middle[1000:2000], middle[2000:3000]\n","        train_latter, valid_latter, test_latter = latter[:1000], latter[1000:2000], latter[2000:3000]\n","\n","    all_quotes = train_middle + valid_middle + test_middle\n","    all_quotes = sorted(list(set(all_quotes)))\n","\n","    y_train = [all_quotes.index(q) for q in train_middle]\n","    y_valid = [all_quotes.index(q) for q in valid_middle]\n","    y_test = [all_quotes.index(q) for q in test_middle]\n","\n","    trains = [train_former, train_middle, train_latter]\n","    valids = [valid_former, valid_middle, valid_latter]\n","    tests = [test_former, test_middle, test_latter]\n","    y = [torch.LongTensor(y_train), torch.LongTensor(y_valid), torch.LongTensor(y_test)]\n","\n","    return trains, valids, tests, y , all_quotes"],"metadata":{"id":"4tDLcHlLd8yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/quoter/data/ancient_chinese.txt\"\n","trains, valids, tests, y, all_quotes = load_data(data_path)\n","\n","# get the Tokenizer used for pretraining model\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8dc6a6fcfe4049d89f08eaaf4e3c06c4","442cf7f5599740fca4b2a9742b8da90b","2f030d14f91a42cbb0c4fdb9e268807a","a2146538ab074343902a6146d2549c52","39815848045b4f4f97ea1367a9dc6fdf","c6129d787f704956b859e54fe9f69f01","ac0ea0291aa34490bf42e8a04a19a279","ab0669fb50ce41578cfa014c12673a24","66de55e46d924303a393aa79380ff2ad","178f525ec3054577b366438f0dfb3ae0","33ca0ae10de648c3b46427a41e4ed13d"]},"id":"Z2ngFzPXeARp","executionInfo":{"status":"ok","timestamp":1670743727564,"user_tz":-540,"elapsed":2163,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"3ef7e699-e260-4a98-93ba-7423681eb835"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/110k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dc6a6fcfe4049d89f08eaaf4e3c06c4"}},"metadata":{}}]},{"cell_type":"code","source":["# Obtained directly from the source code\n","def make_context_tensors(former, latter):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","    mask_ids = []\n","    for f, l in zip(former, latter):\n","        sent = f + \"[MASK]\" + l\n","        encoded_dict = tokenizer.encode_plus(sent,\n","                                             add_special_tokens=True,\n","                                             max_length=150,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict['token_type_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        mask_index = encoded_dict['input_ids'][0].tolist().index(103)\n","        mask_ids.append(mask_index)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    return input_ids, token_type_ids, attention_masks, torch.LongTensor(mask_ids)"],"metadata":{"id":"JlUMs3IkeF_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_input_ids, train_token_type_ids, train_attention_masks, train_mask_ids = make_context_tensors(trains[0], trains[2])\n","valid_input_ids, valid_token_type_ids, valid_attention_masks, valid_mask_ids = make_context_tensors(valids[0], valids[2])"],"metadata":{"id":"ZeE7ea9vF7pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from source code\n","class Dataset(Dataset):\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 quote):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.quote = quote\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.quote is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.quote[\n","                idx]\n","\n","\n","train_dataset = Dataset(input_ids=train_input_ids,\n","                        token_type_ids=train_token_type_ids,\n","                        attention_masks=train_attention_masks,\n","                        mask_ids=train_mask_ids,\n","                        quote=trains[1])\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n","valid_dataset = Dataset(input_ids=valid_input_ids,\n","                        token_type_ids=valid_token_type_ids,\n","                        attention_masks=valid_attention_masks,\n","                        mask_ids=valid_mask_ids,\n","                        quote=valids[1])\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n"],"metadata":{"id":"yNt4kqlWeOWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_quotes(quote, num):\n","    quotes_selcet = all_quotes[:]\n","    quotes_selcet.remove(quote)\n","    quotes = random.sample(quotes_selcet, num)\n","    quotes.append(quote)\n","    random.shuffle(quotes)\n","    return quotes\n","\n","# Obtained directly from the source code\n","def make_quote_tensors(quote):\n","    quotes = generate_quotes(quote, num=sample_num)\n","    label = quotes.index(quote)\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)  # [num, 80]\n","    quote_ids = torch.LongTensor([all_quotes.index(q) for q in quotes])\n","    return input_ids, label, quote_ids\n"],"metadata":{"id":"mSQOsfcSTM9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Context_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, context_input_ids, context_token_type_ids, context_attention_masks, mask_ids):\n","        outputs = self.bert_model(input_ids=context_input_ids,\n","                                  token_type_ids=context_token_type_ids,\n","                                  attention_mask=context_attention_masks)\n","        \n","        last_hidden_state = outputs[0]\n","        all_context = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            mask = self.dropout(mask)\n","            context = mask.unsqueeze(dim=0)\n","            all_context.append(context)\n","\n","        return torch.cat(all_context, dim=0)\n","\n","\n","class Quote_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        # self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, quotes):\n","        quote_tensor = []\n","        labels = []\n","        for quote in quotes:\n","            quote_input_ids, label, quote_ids = make_quote_tensors(quote)\n","            quote_input_ids = quote_input_ids.to(device)\n","            quote_ids = quote_ids.to(device)\n","            outputs = self.bert_model(input_ids=quote_input_ids)\n","            output = torch.mean(outputs[0], dim=1)\n","            \n","            quote_tensor.append(output)\n","            labels.append(label)\n","        quote_tensor = torch.stack(quote_tensor, dim=0)\n","        return quote_tensor, labels\n","\n","\n","class QuotRec_Net(nn.Module):\n","    def __init__(self, context_model, quote_model):\n","        super().__init__()\n","        self.context_model = context_model\n","        self.quote_model = quote_model\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                quotes):\n","        context_output = self.context_model(input_ids, token_type_ids,\n","                                           attention_masks, mask_ids)\n","        context_output = context_output.unsqueeze(dim=1)\n","\n","        quote_output, labels = self.quote_model(quotes)\n","        quote_output = quote_output.permute(0, 2, 1)\n","\n","        outputs = torch.matmul(context_output, quote_output).squeeze(dim=1)\n","        return outputs, torch.LongTensor(labels)\n","\n","context_model = Context_Encoder()\n","quote_model = Quote_Encoder()\n","model = QuotRec_Net(context_model, quote_model)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a364bdc4d49544259e7e249c61f4e77a","028a0373f019409db358c347e8834bd1","d8b8036a6c5843e9ab98af552dc141fc","9ef451ac08a4488eae5aec6ac24fcee7","055e81de2b5c4d3ca04c1fa9ec8b4e28","fc4cc2d869884e02a4d57f7839f95692","25f504cbbd2e4fdebe7247af0b7a1fd6","dad6005a57cb4e279d084525ca7ae13a","f9adf5d0e5e742dc884389ebdacd9dfa","120c361326074beaa50cea23c282efa7","283e685670484c12a7aba0dd8fa5118b","101ef97a2251496ba60a9e0c3080b887","32f551e725304be4bfe55d6014d3fb0b","dc128b911b3b40f2b8787732974ebdd5","a6b5c2a8ecab4dc6941ee6adbe1e75ee","4c4392249da84aa1bbad5408880c2fc1","3c94276c1bb94dadbe3d087e035ae3ca","d237e8834fb34560a95e681f29162175","716ce13829dd48f7a9df1f9496acc553","5e5c8aece889423682801f40f03c9ef0","789817810ea94ee5a4a321ee18c454dd","1e4c98cef11f482298fa4c8e472a3d31"]},"id":"GYFi7GbKeWsN","executionInfo":{"status":"ok","timestamp":1670743916891,"user_tz":-540,"elapsed":19673,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"a495b3fc-10a3-4daa-f9ba-9b233c577af3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/624 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a364bdc4d49544259e7e249c61f4e77a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/412M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101ef97a2251496ba60a9e0c3080b887"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["QuotRec_Net(\n","  (context_model): Context_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (quote_model): Quote_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import math\n","def training(model, epoch, train, valid, device):\n","\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_acc = 0\n","    best_loss = math.inf\n","    losses = []\n","    count = 0\n","\n","    for epoch in tq.tqdm(range(epoch)):\n","        start = time.perf_counter()\n","        total_loss, total_acc = 0, 0\n","        print(\"Epoch: \", epoch + 1)\n","\n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs, labels = model(input_ids, token_type_ids, attention_masks,mask_ids, quotes)\n","            labels = labels.to(device, dtype=torch.long)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, pred = torch.max(outputs.cpu().data, 1)\n","            acc = accuracy_score(pred, labels.cpu())\n","            total_loss += loss.item()\n","            total_acc += acc\n","        print('Train | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_train))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","\n","                outputs, labels = model(input_ids, token_type_ids,attention_masks, mask_ids, quotes)\n","                labels = labels.to(device, dtype=torch.long)\n","                loss = criterion(outputs, labels)\n","                _, pred = torch.max(outputs.cpu().data, 1)\n","\n","                acc = accuracy_score(pred, labels.cpu())\n","                total_loss += loss.item()\n","                total_acc += acc\n","            losses.append(total_loss)\n","            print('Valid | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_valid))\n","\n","            if total_acc >= best_acc and total_loss <= best_loss:\n","                best_acc = total_acc\n","                best_loss = total_loss\n","                if not os.path.exists(\"./model\"):\n","                    os.mkdir(\"./model\")\n","                torch.save(model.quote_model.state_dict(), \"/content/drive/MyDrive/model/ancient_chinese_quote.pth\")\n","                torch.save(model.context_model.state_dict(), \"/content/drive/MyDrive/model/ancient_chinese_context.pth\")\n","                count = 0\n","            elif total_loss > best_loss:\n","                count += 1\n","\n","        end = time.perf_counter()\n","\n","        if count == 3:\n","            print(\"Early Stopping\")\n","            break\n","\n","\n","training(model=model,\n","         epoch=epochs,\n","         train=train_loader,\n","         valid=valid_loader,\n","         device=device)\n","\n","\n","def make_tensors(quotes):\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)\n","    return input_ids\n","\n","\n","quote_input_ids = make_tensors(all_quotes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["58023d0b6f644aebaf67bbfe0c4f8196","63394b5705694887935aafa9a487d306","d9cab0bbf1e2438dbdb8df490d4ce7f5","3aaea614a0c846ee958493fe1910d17e","58d0895df1454d6e84c4aa32d7c90112","03f2744983404812a2215a005ce16b05","734fc72e22574d3194ff5e71c47a07e6","a3498d89e0eb4ae3a5d34766f89b13c3","a3d370bdf13244d1a41ca59be3eb4113","6caf7c944a9b43ee8ac24f831b9b81cb","89c6887e7f754ed7b81e3928134eb5b4"]},"id":"mlczWb0UeeQ2","executionInfo":{"status":"ok","timestamp":1670746218763,"user_tz":-540,"elapsed":1649965,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"5d7587dc-cba9-4b84-fe70-79c5dda2b1e8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58023d0b6f644aebaf67bbfe0c4f8196"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch:  1\n","Train | Loss:1303.78952 Acc:0.228\n","Valid | Loss:1170.85251 Acc:0.314\n","Epoch:  2\n","Train | Loss:874.94655 Acc:0.472\n","Valid | Loss:1373.45870 Acc:0.325\n","Epoch:  3\n","Train | Loss:582.00782 Acc:0.641\n","Valid | Loss:1247.81745 Acc:0.326\n","Epoch:  4\n","Train | Loss:341.18348 Acc:0.780\n","Valid | Loss:1688.63169 Acc:0.316\n","Early Stopping\n"]}]},{"cell_type":"code","source":["# Generate sentence vector for quotes\n","quote_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","model_dict = quote_model.state_dict()\n","save_model_state = torch.load(\"/content/drive/MyDrive/model/ancient_chinese_quote.pth\")\n","\n","state_dict = {k[11:]: v for k, v in save_model_state.items() if k[11:] in model_dict.keys()}\n","model_dict.update(state_dict)\n","quote_model.load_state_dict(model_dict)\n","\n","quote_model = quote_model.to(device)\n","quote_input_ids = quote_input_ids.to(device)\n","\n","quote_embeddings = []\n","quote_model.eval()\n","\n","with torch.no_grad():\n","    for input_ids in quote_input_ids:\n","        input_ids = input_ids.unsqueeze(dim=0)\n","        outputs = quote_model(input_ids=input_ids)\n","        quote_tensor = torch.mean(outputs[0], dim=1)\n","        quote_embeddings.append(quote_tensor)\n","    quote_embeddings = torch.cat(quote_embeddings, dim=0)\n"],"metadata":{"id":"BgODzAlUelT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the mask method for training\n","class QuotRecNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks,\n","                mask_ids, quote_tensor):\n","        outputs = self.bert_model(input_ids=input_ids,\n","                                  token_type_ids=token_type_ids,\n","                                  attention_mask=attention_masks)\n","        last_hidden_state = outputs[0]\n","        all_outputs = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            context = self.dropout(mask)\n","            context = context.unsqueeze(dim=0)\n","            output = torch.mm(context, quote_tensor.t())\n","            all_outputs.append(output)\n","        all_outputs = torch.cat(all_outputs, dim=0)\n","        return all_outputs\n","\n","\n","model = QuotRecNet()\n","model.to(device)\n"],"metadata":{"id":"P82Gpy9MTjVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670746376461,"user_tz":-540,"elapsed":2581,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"193b32ed-30ba-4917-e683-aeeb55dfeae9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRecNet(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Evaluation Metrics\n","# Rank\n","def rank_gold(predicts, golds):\n","  ranks = []\n","  ps = predicts.data.cpu().numpy()\n","  gs = golds.cpu().numpy()\n","  for i in range(len(ps)):\n","    predict = ps[i]\n","    gold_index = gs[i]\n","    predict_value = predict[gold_index]\n","    predict_sort = sorted(predict, reverse=True)\n","    predict_index = predict_sort.index(predict_value)\n","    if predict_index == -1:\n","        break\n","    ranks.append(predict_index)\n","  return ranks\n","\n","\n","# NDCG@5\n","def get_NDCG(ranks):\n","    total = 0.0\n","    for r in ranks:\n","        if r < 5:  # k=5\n","            total += 1.0 / np.log2(r + 2)\n","    return total / len(ranks)\n","\n","\n","# get recall@k\n","def recall(predicts, golds):\n","    predicts = predicts.data.cpu().numpy()\n","    golds = list(golds)\n","    predicts_index = list(np.argsort(-predicts, axis=1))\n","    predicts_index = [list(element) for element in predicts_index]\n","    recall_values = [0, 0, 0, 0, 0, 0, 0] # 1, 3, 5, 10, 20, 30, 100, 300, 500\n","    recalls = [1, 3, 5, 10, 20, 30, 100]\n","\n","    for i in range(len(golds)):\n","        gold_value_index = predicts_index[i].index(golds[i])\n","        for val in range(len(recalls)):\n","            if gold_value_index < recalls[val]:\n","                recall_values[val] += 1\n","\n","    return recall_values\n","\n","def get_mrr(ranks):\n","    return np.average([1.0 / (r + 1) for r in ranks])"],"metadata":{"id":"4OvvDjTWe0ke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training_mask(model, epoch, train, valid, quote_tensor, device):\n","    learning_rate = 3e-5\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_MRR = 0\n","    count = 0\n","    quote_tensor = quote_tensor.to(device)\n","    for epoch in range(epoch):\n","        start = time.perf_counter()\n","        print(\"Epoch: \", epoch + 1)\n","        total_loss, total_MRR, total_NDCG = 0, 0, 0\n","        \n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","  \n","            ranks = rank_gold(outputs, labels)\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","        end = time.perf_counter()\n","        print('Epoch running time :{:.0f}'.format(end - start))\n","        print('Train | Loss:{:.3f} MRR: {:.3f} NDCG: {:.3f}'.format(total_loss, total_MRR/len_train, total_NDCG/len_train))\n","\n","        # validation\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_MRR, total_NDCG = 0, 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.long)\n","                outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","                loss = criterion(outputs, labels)\n","                \n","                ranks = rank_gold(outputs, labels)\n","                MRR = get_mrr(ranks)\n","                NDCG = get_NDCG(ranks)\n","                \n","                total_loss += loss.item()\n","                total_MRR += MRR\n","                total_NDCG += NDCG\n","            print(\"Valid | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f}\".format(total_loss, total_MRR / len_valid,total_NDCG / len_valid))\n","        \n","        if total_MRR > best_MRR:\n","            best_MRR = total_MRR\n","            torch.save(model, \"/content/drive/MyDrive/model/model_ancient_chinese.model\")\n","            count = 0\n","        else:\n","            learning_rate = learning_rate * 0.9\n","            count += 1\n","        \n","        # Early Stopping\n","        if count == 3:\n","            break"],"metadata":{"id":"ndwGb997fFVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask Dataset and DataLoader\n","class Dataset_Mask(Dataset):\n","\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 y):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.label = y\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.label[\n","                idx]\n","\n","\n","print(\"loading train and valid dataloader ...\")\n","train_dataset_mask = Dataset_Mask(input_ids=train_input_ids,\n","                                  token_type_ids=train_token_type_ids,\n","                                  attention_masks=train_attention_masks,\n","                                  mask_ids=train_mask_ids,\n","                                  y=y[0])\n","train_loader_mask = DataLoader(dataset=train_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","valid_dataset_mask = Dataset_Mask(input_ids=valid_input_ids,\n","                                  token_type_ids=valid_token_type_ids,\n","                                  attention_masks=valid_attention_masks,\n","                                  mask_ids=valid_mask_ids,\n","                                  y=y[1])\n","valid_loader_mask = DataLoader(dataset=valid_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","print(\"start traing......\")\n","training_mask(model=model,\n","              epoch=epochs,\n","              train=train_loader_mask,\n","              valid=valid_loader_mask,\n","              quote_tensor=quote_embeddings,\n","              device=device)"],"metadata":{"id":"EMMwKZXYe5mG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"61e54ef1-6319-4897-d75a-eee5ce46a35b","executionInfo":{"status":"ok","timestamp":1670747228900,"user_tz":-540,"elapsed":132014,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading train and valid dataloader ...\n","start traing......\n","Epoch:  1\n","Epoch running time :46\n","Train | Loss:2915.859 MRR: 0.137 NDCG: 0.130\n","Valid | Loss:3131.98233 MRR: 0.098 NDCG: 0.092\n","Epoch:  2\n","Epoch running time :46\n","Train | Loss:2101.698 MRR: 0.332 NDCG: 0.344\n","Valid | Loss:3153.21286 MRR: 0.118 NDCG: 0.114\n","Epoch:  3\n","Epoch running time :46\n","Train | Loss:1430.561 MRR: 0.560 NDCG: 0.585\n","Valid | Loss:3163.52379 MRR: 0.124 NDCG: 0.119\n","Epoch:  4\n","Epoch running time :46\n","Train | Loss:992.675 MRR: 0.733 NDCG: 0.758\n","Valid | Loss:3182.26119 MRR: 0.134 NDCG: 0.131\n","Epoch:  5\n","Epoch running time :46\n","Train | Loss:698.621 MRR: 0.869 NDCG: 0.889\n","Valid | Loss:3148.63998 MRR: 0.135 NDCG: 0.129\n","Epoch:  6\n","Epoch running time :46\n","Train | Loss:492.925 MRR: 0.934 NDCG: 0.947\n","Valid | Loss:3181.20285 MRR: 0.135 NDCG: 0.130\n","Epoch:  7\n","Epoch running time :46\n","Train | Loss:339.785 MRR: 0.975 NDCG: 0.981\n","Valid | Loss:3161.83142 MRR: 0.135 NDCG: 0.130\n","Epoch:  8\n","Epoch running time :46\n","Train | Loss:273.550 MRR: 0.985 NDCG: 0.988\n","Valid | Loss:3175.29989 MRR: 0.143 NDCG: 0.136\n","Epoch:  9\n","Epoch running time :46\n","Train | Loss:219.308 MRR: 0.989 NDCG: 0.992\n","Valid | Loss:3179.61200 MRR: 0.136 NDCG: 0.132\n","Epoch:  10\n","Epoch running time :46\n","Train | Loss:181.646 MRR: 0.994 NDCG: 0.996\n","Valid | Loss:3204.91537 MRR: 0.144 NDCG: 0.141\n","Epoch:  11\n","Epoch running time :46\n","Train | Loss:160.506 MRR: 0.993 NDCG: 0.995\n","Valid | Loss:3185.76754 MRR: 0.143 NDCG: 0.135\n","Epoch:  12\n","Epoch running time :46\n","Train | Loss:127.934 MRR: 0.997 NDCG: 0.998\n","Valid | Loss:3183.94937 MRR: 0.143 NDCG: 0.137\n","Epoch:  13\n","Epoch running time :46\n","Train | Loss:114.812 MRR: 0.999 NDCG: 0.999\n","Valid | Loss:3252.91229 MRR: 0.139 NDCG: 0.134\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, quote_tensor, device):\n","    model.eval()\n","    t_batch = len(test_loader)\n","    criterion = nn.CrossEntropyLoss()\n","    quote_tensor = quote_tensor.to(device)\n","    with torch.no_grad():\n","        total_loss, total_MRR, total_NDCG, total_ranks = 0, 0, 0, 0\n","        total_recalls = [0, 0, 0, 0, 0, 0, 0]\n","        all_ranks = []\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            \n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            \n","            ranks = rank_gold(outputs, labels)\n","            all_ranks += ranks\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            recalls = recall(outputs, labels)\n","            \n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","            total_ranks += np.sum(ranks)\n","            total_recalls = [x + y for x, y in zip(total_recalls, recalls)]\n","\n","        total_recalls = [element / len(y[2]) for element in total_recalls]\n","\n","        print(\n","            \"Test | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f} Mean Rank: {:.0f} Median Rank: {:.0f} Variance: {:.0f}\"\n","            .format(total_loss, total_MRR / t_batch,\n","                    total_NDCG / t_batch, np.mean(all_ranks),\n","                    np.median(all_ranks)+1,\n","                    np.std(all_ranks)))\n","        print(\"Recall@[1,3,5,10,20,30,100]: \" + str(total_recalls))\n","        \n","\n","test_input_ids, test_token_type_ids, test_attention_masks, test_mask_ids = make_context_tensors(tests[0], tests[2])\n","test_dataset_mask = Dataset_Mask(input_ids=test_input_ids,\n","                                 token_type_ids=test_token_type_ids,\n","                                 attention_masks=test_attention_masks,\n","                                 mask_ids=test_mask_ids,\n","                                 y=y[2])\n","test_loader_mask = DataLoader(dataset=test_dataset_mask,\n","                              batch_size=batch,\n","                              num_workers=2)\n","\n","model = torch.load('/content/drive/MyDrive/model/model_ancient_chinese.model')\n","model.to(device)\n","test(model=model,\n","     test_loader=test_loader_mask,\n","     quote_tensor=quote_embeddings,\n","     device=device)"],"metadata":{"id":"w_WTyan4fBLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670747391727,"user_tz":-540,"elapsed":18403,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"82df5ca4-d444-4848-800f-198f6046176a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test | Loss:3240.68479 MRR: 0.129 NDCG: 0.123 Mean Rank: 240 Median Rank: 103 Variance: 317\n","Recall@[1,3,5,10,20,30,100]: [0.081, 0.138, 0.16, 0.213, 0.28, 0.325, 0.493]\n"]}]}]}