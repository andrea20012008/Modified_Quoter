{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"45cce8a02c1f416ea42484ca9294f77b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f02157bc3a9241b997be556457eb92d1","IPY_MODEL_2ba4541e0e0442f887f6d26e98314ac1","IPY_MODEL_0bbffb4d2222462d957d1f5e24224208"],"layout":"IPY_MODEL_52e7550cc6c64bf9ad35b58cdc58aed9"}},"f02157bc3a9241b997be556457eb92d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_341a4405e07b4688beacc39925be1185","placeholder":"​","style":"IPY_MODEL_9f03194110ed46ec9d6686c37309c83e","value":"Downloading: 100%"}},"2ba4541e0e0442f887f6d26e98314ac1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f9a0756627d4062baa1c690f73ebb2e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bf1c7fd06244130ac0c38040a82ed02","value":231508}},"0bbffb4d2222462d957d1f5e24224208":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a2cdaa5c1ef4491b65b55dd44c34c41","placeholder":"​","style":"IPY_MODEL_773566f1644944768f8f30d8e1fef786","value":" 232k/232k [00:00&lt;00:00, 354kB/s]"}},"52e7550cc6c64bf9ad35b58cdc58aed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341a4405e07b4688beacc39925be1185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f03194110ed46ec9d6686c37309c83e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f9a0756627d4062baa1c690f73ebb2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf1c7fd06244130ac0c38040a82ed02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a2cdaa5c1ef4491b65b55dd44c34c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"773566f1644944768f8f30d8e1fef786":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cfe40652c6f4045bd8a9a2558034766":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa40565734064867828ebad4e82c331c","IPY_MODEL_3e3e3213009240f3817e7b306c835b33","IPY_MODEL_1d2138dc762c4b4b899c48ac0a963896"],"layout":"IPY_MODEL_c3eeb6e30ffb488da442d033edca3c2f"}},"aa40565734064867828ebad4e82c331c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d65ee3a4e5e043ef89462fed90f713fd","placeholder":"​","style":"IPY_MODEL_6e35eddc916b4441a740e6f18652705c","value":"Downloading: 100%"}},"3e3e3213009240f3817e7b306c835b33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc1719c942e047db9a03582874ae1fb5","max":433,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59d799031c704b7e8a4572d3ead9f843","value":433}},"1d2138dc762c4b4b899c48ac0a963896":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_865471e984f34f45a6a915b9dc8d70d5","placeholder":"​","style":"IPY_MODEL_c5787c4226dc4a7e9e0c327e5b4a6f0a","value":" 433/433 [00:00&lt;00:00, 16.1kB/s]"}},"c3eeb6e30ffb488da442d033edca3c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65ee3a4e5e043ef89462fed90f713fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e35eddc916b4441a740e6f18652705c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc1719c942e047db9a03582874ae1fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d799031c704b7e8a4572d3ead9f843":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"865471e984f34f45a6a915b9dc8d70d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5787c4226dc4a7e9e0c327e5b4a6f0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfdf6c0e5b5b453196e9b5cd576dab60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d46064098ab4b35aa924b98d8333303","IPY_MODEL_51a04f6022fd4da38004647ad4a3d760","IPY_MODEL_0361d952b9004a6d937ef8f3165dafe9"],"layout":"IPY_MODEL_745eca26397e4721bde23605ff6aa80d"}},"5d46064098ab4b35aa924b98d8333303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc14f09e6ed94eec9feae3d9e534323c","placeholder":"​","style":"IPY_MODEL_b5677114c6fd4eb9867004e7cfcb33c6","value":"Downloading: 100%"}},"51a04f6022fd4da38004647ad4a3d760":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b01964f97d4eab9a689bbfd6cb143b","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f3acaa19fbb47cf83c0c94bacd1615d","value":440473133}},"0361d952b9004a6d937ef8f3165dafe9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b6321b201442acbc4cbc2415003d07","placeholder":"​","style":"IPY_MODEL_437ebdece46248ccab85432767969ebc","value":" 440M/440M [00:06&lt;00:00, 79.7MB/s]"}},"745eca26397e4721bde23605ff6aa80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc14f09e6ed94eec9feae3d9e534323c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5677114c6fd4eb9867004e7cfcb33c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43b01964f97d4eab9a689bbfd6cb143b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f3acaa19fbb47cf83c0c94bacd1615d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0b6321b201442acbc4cbc2415003d07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"437ebdece46248ccab85432767969ebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00ac89c7a9a348e1bd9809145045f8ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_704fb0e32d51450384d3b5d3215f3ea3","IPY_MODEL_7faeaeb1a9f3476982a446e2472661d1","IPY_MODEL_79f4905d31b8450b81153d2ef18eb5a9"],"layout":"IPY_MODEL_0b934008dfe942568223b06e520cb50a"}},"704fb0e32d51450384d3b5d3215f3ea3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_539cc4838e194843959bfa7afea4947a","placeholder":"​","style":"IPY_MODEL_fdaf25fa50c14351b50eb4151ba3e89c","value":"  5%"}},"7faeaeb1a9f3476982a446e2472661d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2263a5d376f94ab894b67372932e4176","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3b53612e58d49e1b973b056ec80d0b7","value":2}},"79f4905d31b8450b81153d2ef18eb5a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_234aa31dfa15414fa74dcf766399ceac","placeholder":"​","style":"IPY_MODEL_9275124ee2cd4f70aaffbcae2e72cf92","value":" 2/40 [14:13&lt;4:30:19, 426.82s/it]"}},"0b934008dfe942568223b06e520cb50a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"539cc4838e194843959bfa7afea4947a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdaf25fa50c14351b50eb4151ba3e89c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2263a5d376f94ab894b67372932e4176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b53612e58d49e1b973b056ec80d0b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"234aa31dfa15414fa74dcf766399ceac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9275124ee2cd4f70aaffbcae2e72cf92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_MuaoJDnGmY3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670754518752,"user_tz":-540,"elapsed":23583,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"c6d2bc0f-224e-4747-ae0b-c6f958b03648"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers==3.0.2\n","!pip install OpenHowNet==0.0.1a11\n","!pip install nltk==3.5\n","#import transformers1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_uSElwkIzEe","executionInfo":{"status":"ok","timestamp":1670754540645,"user_tz":-540,"elapsed":18861,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"3ad7359e-7ff6-489b-d63e-e4a191ef7cb3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 15.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 56.8 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 61.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 62.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=318cf58cd1a0a6eb3be352b3ec678b47ca1260fd15a79900b81745c887b93b65\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting OpenHowNet==0.0.1a11\n","  Downloading OpenHowNet-0.0.1a11-py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.23.0)\n","Collecting anytree\n","  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 713 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (4.64.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from anytree->OpenHowNet==0.0.1a11) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (3.0.4)\n","Installing collected packages: anytree, OpenHowNet\n","Successfully installed OpenHowNet-0.0.1a11 anytree-2.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.5\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 15.1 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (4.64.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434693 sha256=03d88fd29e42f25bb6bc5bebf3d8a393d0f0822318eda046e2d83372cb1e81ae\n","  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed nltk-3.5\n"]}]},{"cell_type":"code","source":["import tqdm.notebook as tq\n","import torch\n","from transformers import BertTokenizer, BertModel, AdamW, BertSememeModel\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import os\n","import time\n","import random\n","from sklearn.metrics import accuracy_score\n","import numpy as np"],"metadata":{"id":"IO0wePPWItfY","executionInfo":{"status":"ok","timestamp":1670754675278,"user_tz":-540,"elapsed":6484,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["random.seed(42)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch = 2\n","sample_num = 19\n","learning_rate = 3e-5\n","epochs = 40\n","max_length = 80"],"metadata":{"id":"gS6wVAZFJbZ6","executionInfo":{"status":"ok","timestamp":1670754678774,"user_tz":-540,"elapsed":3,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#our implementation\n","def load_data(path):\n","    with open(path, 'r', encoding='utf-8') as f:\n","        former, middle, latter = [], [], []\n","\n","        lines = f.readlines()\n","        for line in lines:\n","            line = line.strip().lower().split('\\t')\n","            former.append(line[0])\n","            middle.append(line[1])\n","            latter.append(line[2])\n","        \n","        train_former, valid_former, test_former = former[:1000], former[1000:2000], former[2000:3000]\n","        train_middle, valid_middle, test_middle = middle[:1000], middle[1000:2000], middle[2000:3000]\n","        train_latter, valid_latter, test_latter = latter[:1000], latter[1000:2000], latter[2000:3000]\n","\n","    all_quotes = train_middle + valid_middle + test_middle\n","    all_quotes = sorted(list(set(all_quotes)))\n","\n","    y_train = [all_quotes.index(q) for q in train_middle]\n","    y_valid = [all_quotes.index(q) for q in valid_middle]\n","    y_test = [all_quotes.index(q) for q in test_middle]\n","\n","    trains = [train_former, train_middle, train_latter]\n","    valids = [valid_former, valid_middle, valid_latter]\n","    tests = [test_former, test_middle, test_latter]\n","    y = [torch.LongTensor(y_train), torch.LongTensor(y_valid), torch.LongTensor(y_test)]\n","\n","    return trains, valids, tests, y , all_quotes"],"metadata":{"id":"pZ8wYFuFJf4k","executionInfo":{"status":"ok","timestamp":1670754682129,"user_tz":-540,"elapsed":419,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/quoter/data/english.txt\"\n","trains, valids, tests, y, all_quotes = load_data(data_path)\n","\n","# get the Tokenizer used for pretraining model\n","PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"],"metadata":{"id":"BoNdkypTJ3co","executionInfo":{"status":"ok","timestamp":1670754687329,"user_tz":-540,"elapsed":3749,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["45cce8a02c1f416ea42484ca9294f77b","f02157bc3a9241b997be556457eb92d1","2ba4541e0e0442f887f6d26e98314ac1","0bbffb4d2222462d957d1f5e24224208","52e7550cc6c64bf9ad35b58cdc58aed9","341a4405e07b4688beacc39925be1185","9f03194110ed46ec9d6686c37309c83e","3f9a0756627d4062baa1c690f73ebb2e","7bf1c7fd06244130ac0c38040a82ed02","6a2cdaa5c1ef4491b65b55dd44c34c41","773566f1644944768f8f30d8e1fef786"]},"outputId":"2584569f-e0ab-4be9-952b-b9d32bf1bac0"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45cce8a02c1f416ea42484ca9294f77b"}},"metadata":{}}]},{"cell_type":"code","source":["# Obtained directly from the source code\n","def make_context_tensors(former, latter):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","    mask_ids = []\n","    for f, l in zip(former, latter):\n","        #sent = f + \"[MASK]\" + l\n","        sent = \"[MASK]\" + l\n","        encoded_dict = tokenizer.encode_plus(sent,\n","                                             add_special_tokens=True,\n","                                             max_length=150,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict['token_type_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        mask_index = encoded_dict['input_ids'][0].tolist().index(103)\n","        mask_ids.append(mask_index)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    return input_ids, token_type_ids, attention_masks, torch.LongTensor(mask_ids)"],"metadata":{"id":"jwYlBPWmKLJS","executionInfo":{"status":"ok","timestamp":1670754694340,"user_tz":-540,"elapsed":1,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_input_ids, train_token_type_ids, train_attention_masks, train_mask_ids = make_context_tensors(trains[0], trains[2])\n","valid_input_ids, valid_token_type_ids, valid_attention_masks, valid_mask_ids = make_context_tensors(valids[0], valids[2])"],"metadata":{"id":"Q5kvkewwKzdZ","executionInfo":{"status":"ok","timestamp":1670754697608,"user_tz":-540,"elapsed":1662,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from source code\n","class Dataset(Dataset):\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 quote):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.quote = quote\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.quote is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.quote[\n","                idx]\n","\n","\n","train_dataset = Dataset(input_ids=train_input_ids,\n","                        token_type_ids=train_token_type_ids,\n","                        attention_masks=train_attention_masks,\n","                        mask_ids=train_mask_ids,\n","                        quote=trains[1])\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n","valid_dataset = Dataset(input_ids=valid_input_ids,\n","                        token_type_ids=valid_token_type_ids,\n","                        attention_masks=valid_attention_masks,\n","                        mask_ids=valid_mask_ids,\n","                        quote=valids[1])\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n"],"metadata":{"id":"HFhIkW3eK6jf","executionInfo":{"status":"ok","timestamp":1670754697609,"user_tz":-540,"elapsed":2,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def generate_quotes(quote, num):\n","    quotes_selcet = all_quotes[:]\n","    quotes_selcet.remove(quote)\n","    quotes = random.sample(quotes_selcet, num)\n","    quotes.append(quote)\n","    random.shuffle(quotes)\n","    return quotes\n","# Obtained directly from the source code\n","def make_quote_tensors(quote):\n","    quotes = generate_quotes(quote, num=sample_num)\n","    label = quotes.index(quote)\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)  # [num, 80]\n","    quote_ids = torch.LongTensor([all_quotes.index(q) for q in quotes])\n","    return input_ids, label, quote_ids\n"],"metadata":{"id":"FTfMacv5LFCU","executionInfo":{"status":"ok","timestamp":1670754698135,"user_tz":-540,"elapsed":1,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class Context_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, context_input_ids, context_token_type_ids, context_attention_masks, mask_ids):\n","        outputs = self.bert_model(input_ids=context_input_ids,\n","                                  token_type_ids=context_token_type_ids,\n","                                  attention_mask=context_attention_masks)\n","        \n","        last_hidden_state = outputs[0]\n","        all_context = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            mask = self.dropout(mask)\n","            context = mask.unsqueeze(dim=0)\n","            all_context.append(context)\n","\n","        return torch.cat(all_context, dim=0)\n","\n","\n","class Quote_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertSememeModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        #self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        # self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, quotes):\n","        quote_tensor = []\n","        labels = []\n","        for quote in quotes:\n","            quote_input_ids, label, quote_ids = make_quote_tensors(quote)\n","            quote_input_ids = quote_input_ids.to(device)\n","            quote_ids = quote_ids.to(device)\n","            outputs = self.bert_model(input_ids=quote_input_ids,quote_ids=quote_ids)\n","            output = torch.mean(outputs[0], dim=1)\n","            \n","            quote_tensor.append(output)\n","            labels.append(label)\n","        quote_tensor = torch.stack(quote_tensor, dim=0)\n","        return quote_tensor, labels\n","\n","\n","class QuotRec_Net(nn.Module):\n","    def __init__(self, context_model, quote_model):\n","        super().__init__()\n","        self.context_model = context_model\n","        self.quote_model = quote_model\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                quotes):\n","        context_output = self.context_model(input_ids, token_type_ids,\n","                                           attention_masks, mask_ids)\n","        context_output = context_output.unsqueeze(dim=1)\n","\n","        quote_output, labels = self.quote_model(quotes)\n","        quote_output = quote_output.permute(0, 2, 1)\n","\n","        outputs = torch.matmul(context_output, quote_output).squeeze(dim=1)\n","        return outputs, torch.LongTensor(labels)\n","\n","context_model = Context_Encoder()\n","quote_model = Quote_Encoder()\n","model = QuotRec_Net(context_model, quote_model)\n","model.to(device)"],"metadata":{"id":"GFWx2djlLKXa","executionInfo":{"status":"ok","timestamp":1670754720430,"user_tz":-540,"elapsed":19851,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0cfe40652c6f4045bd8a9a2558034766","aa40565734064867828ebad4e82c331c","3e3e3213009240f3817e7b306c835b33","1d2138dc762c4b4b899c48ac0a963896","c3eeb6e30ffb488da442d033edca3c2f","d65ee3a4e5e043ef89462fed90f713fd","6e35eddc916b4441a740e6f18652705c","cc1719c942e047db9a03582874ae1fb5","59d799031c704b7e8a4572d3ead9f843","865471e984f34f45a6a915b9dc8d70d5","c5787c4226dc4a7e9e0c327e5b4a6f0a","dfdf6c0e5b5b453196e9b5cd576dab60","5d46064098ab4b35aa924b98d8333303","51a04f6022fd4da38004647ad4a3d760","0361d952b9004a6d937ef8f3165dafe9","745eca26397e4721bde23605ff6aa80d","cc14f09e6ed94eec9feae3d9e534323c","b5677114c6fd4eb9867004e7cfcb33c6","43b01964f97d4eab9a689bbfd6cb143b","8f3acaa19fbb47cf83c0c94bacd1615d","c0b6321b201442acbc4cbc2415003d07","437ebdece46248ccab85432767969ebc"]},"outputId":"2e506434-d71c-4ce4-d564-906f0edd79f3"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cfe40652c6f4045bd8a9a2558034766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfdf6c0e5b5b453196e9b5cd576dab60"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:transformers.modeling_utils:Some weights of BertSememeModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.sememe_embeddings.lut.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["QuotRec_Net(\n","  (context_model): Context_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (quote_model): Quote_Encoder(\n","    (bert_model): BertSememeModel(\n","      (embeddings): BertSememeEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (sememe_embeddings): SememeEmbeddings(\n","          (lut): Embedding(1756, 768)\n","        )\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#our training\n","import math\n","def training(model, epoch, train, valid, device):\n","\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_acc = 0\n","    best_loss = math.inf\n","    losses = []\n","    count = 0\n","\n","    for epoch in tq.tqdm(range(epoch)):\n","        start = time.perf_counter()\n","        total_loss, total_acc = 0, 0\n","        print(\"Epoch: \", epoch + 1)\n","\n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs, labels = model(input_ids, token_type_ids, attention_masks,mask_ids, quotes)\n","            labels = labels.to(device, dtype=torch.long)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, pred = torch.max(outputs.cpu().data, 1)\n","            acc = accuracy_score(pred, labels.cpu())\n","            total_loss += loss.item()\n","            total_acc += acc\n","        print('Train | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_train))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","\n","                outputs, labels = model(input_ids, token_type_ids,attention_masks, mask_ids, quotes)\n","                labels = labels.to(device, dtype=torch.long)\n","                loss = criterion(outputs, labels)\n","                _, pred = torch.max(outputs.cpu().data, 1)\n","\n","                acc = accuracy_score(pred, labels.cpu())\n","                total_loss += loss.item()\n","                total_acc += acc\n","            losses.append(total_loss)\n","            print('Valid | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_valid))\n","\n","            if total_acc >= best_acc and total_loss <= best_loss:\n","                best_acc = total_acc\n","                best_loss = total_loss\n","                if not os.path.exists(\"./model\"):\n","                    os.mkdir(\"./model\")\n","                torch.save(model.quote_model.state_dict(), \"/content/drive/MyDrive/model/english_quote.pth\")\n","                torch.save(model.context_model.state_dict(), \"/content/drive/MyDrive/model/english_context.pth\")\n","                count = 0\n","            elif total_loss > best_loss:\n","                count += 1\n","\n","        end = time.perf_counter()\n","\n","        if count == 3:\n","            print(\"Early Stopping\")\n","            break\n","\n","\n","training(model=model,\n","         epoch=epochs,\n","         train=train_loader,\n","         valid=valid_loader,\n","         device=device)\n","\n","\n","def make_tensors(quotes):\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)\n","    return input_ids\n","\n","\n","quote_input_ids = make_tensors(all_quotes)\n"],"metadata":{"id":"sunqFN7dLLyD","colab":{"base_uri":"https://localhost:8080/","height":174,"referenced_widgets":["00ac89c7a9a348e1bd9809145045f8ee","704fb0e32d51450384d3b5d3215f3ea3","7faeaeb1a9f3476982a446e2472661d1","79f4905d31b8450b81153d2ef18eb5a9","0b934008dfe942568223b06e520cb50a","539cc4838e194843959bfa7afea4947a","fdaf25fa50c14351b50eb4151ba3e89c","2263a5d376f94ab894b67372932e4176","d3b53612e58d49e1b973b056ec80d0b7","234aa31dfa15414fa74dcf766399ceac","9275124ee2cd4f70aaffbcae2e72cf92"]},"outputId":"d5f0aaf4-9e89-4391-d888-c067c11e18a6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ac89c7a9a348e1bd9809145045f8ee"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch:  1\n","Train | Loss:1286.78417 Acc:0.225\n","Valid | Loss:1133.26035 Acc:0.324\n","Epoch:  2\n","Train | Loss:707.19203 Acc:0.569\n","Valid | Loss:1146.13535 Acc:0.342\n","Epoch:  3\n"]}]},{"cell_type":"code","source":["# Generate sentence vector for quotes\n","quote_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","model_dict = quote_model.state_dict()\n","save_model_state = torch.load(\"/content/drive/MyDrive/model/english_quote.pth\")\n","\n","state_dict = {k[11:]: v for k, v in save_model_state.items() if k[11:] in model_dict.keys()}\n","model_dict.update(state_dict)\n","quote_model.load_state_dict(model_dict)\n","\n","quote_model = quote_model.to(device)\n","quote_input_ids = quote_input_ids.to(device)\n","\n","quote_embeddings = []\n","quote_model.eval()\n","\n","with torch.no_grad():\n","    for input_ids in quote_input_ids:\n","        input_ids = input_ids.unsqueeze(dim=0)\n","        outputs = quote_model(input_ids=input_ids)\n","        quote_tensor = torch.mean(outputs[0], dim=1)\n","        quote_embeddings.append(quote_tensor)\n","    quote_embeddings = torch.cat(quote_embeddings, dim=0)\n"],"metadata":{"id":"Dh2oxHGqLgNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the mask method for training\n","class QuotRecNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks,\n","                mask_ids, quote_tensor):\n","        outputs = self.bert_model(input_ids=input_ids,\n","                                  token_type_ids=token_type_ids,\n","                                  attention_mask=attention_masks)\n","        last_hidden_state = outputs[0]\n","        all_outputs = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            context = self.dropout(mask)\n","            context = context.unsqueeze(dim=0)\n","            output = torch.mm(context, quote_tensor.t())\n","            all_outputs.append(output)\n","        all_outputs = torch.cat(all_outputs, dim=0)\n","        return all_outputs\n","\n","\n","model = QuotRecNet()\n","model.to(device)\n"],"metadata":{"id":"sxAEotDGLknS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670751901573,"user_tz":-540,"elapsed":2364,"user":{"displayName":"bertenglish sememe","userId":"09784491746436435551"}},"outputId":"69ff24f3-8928-47ee-fe8e-a5f7984b14c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRecNet(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Evaluation Metrics\n","# Rank\n","def rank_gold(predicts, golds):\n","  ranks = []\n","  ps = predicts.data.cpu().numpy()\n","  gs = golds.cpu().numpy()\n","  for i in range(len(ps)):\n","      predict = ps[i]\n","      gold_index = gs[i]\n","      predict_value = predict[gold_index]\n","      predict_sort = sorted(predict, reverse=True)\n","      predict_index = predict_sort.index(predict_value)\n","      if predict_index == -1:\n","          break\n","      ranks.append(predict_index)\n","  return ranks\n","\n","\n","# NDCG@5\n","def get_NDCG(ranks):\n","    total = 0.0\n","    for r in ranks:\n","        if r < 5:  # k=5\n","            total += 1.0 / np.log2(r + 2)\n","    return total / len(ranks)\n","\n","\n","# get recall@k\n","def recall(predicts, golds):\n","    predicts = predicts.data.cpu().numpy()\n","    golds = list(golds)\n","    predicts_index = list(np.argsort(-predicts, axis=1))\n","    predicts_index = [list(element) for element in predicts_index]\n","    recall_values = [0, 0, 0, 0, 0, 0, 0] # 1, 3, 5, 10, 20, 30, 100, 300, 500\n","    recalls = [1, 3, 5, 10, 20, 30, 100]\n","\n","    for i in range(len(golds)):\n","        gold_value_index = predicts_index[i].index(golds[i])\n","        for val in range(len(recalls)):\n","            if gold_value_index < recalls[val]:\n","                recall_values[val] += 1\n","\n","    return recall_values\n","def get_mrr(ranks):\n","    return np.average([1.0 / (r + 1) for r in ranks])"],"metadata":{"id":"eFcKm2NqLlR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training_mask(model, epoch, train, valid, quote_tensor, device):\n","    learning_rate = 3e-5\n","    \n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_MRR = 0\n","    count = 0\n","    quote_tensor = quote_tensor.to(device)\n","    for epoch in range(epoch):\n","        start = time.perf_counter()\n","        print(\"Epoch: \", epoch + 1)\n","        total_loss, total_MRR, total_NDCG = 0, 0, 0\n","        \n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","  \n","            ranks = rank_gold(outputs, labels)\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","        end = time.perf_counter()\n","        print('Epoch running time :{:.0f}'.format(end - start))\n","        print('Train | Loss:{:.3f} MRR: {:.3f} NDCG: {:.3f}'.format(total_loss, total_MRR/len_train, total_NDCG/len_train))\n","\n","        # validation\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_MRR, total_NDCG = 0, 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.long)\n","                outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","                loss = criterion(outputs, labels)\n","                \n","                ranks = rank_gold(outputs, labels)\n","                MRR = get_mrr(ranks)\n","                NDCG = get_NDCG(ranks)\n","                \n","                total_loss += loss.item()\n","                total_MRR += MRR\n","                total_NDCG += NDCG\n","            print(\"Valid | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f}\".format(total_loss, total_MRR / len_valid,total_NDCG / len_valid))\n","        \n","        if total_MRR > best_MRR:\n","            best_MRR = total_MRR\n","            torch.save(model, \"/content/drive/MyDrive/model/model_english.model\")\n","            count = 0\n","        else:\n","            learning_rate = learning_rate * 0.9\n","            count += 1\n","        \n","        # Early Stopping\n","        if count == 3:\n","            break"],"metadata":{"id":"Ykg3_dhiLprQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask Dataset and DataLoader\n","class Dataset_Mask(Dataset):\n","\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 y):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.label = y\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.label[\n","                idx]\n","\n","\n","print(\"loading train and valid dataloader ...\")\n","train_dataset_mask = Dataset_Mask(input_ids=train_input_ids,\n","                                  token_type_ids=train_token_type_ids,\n","                                  attention_masks=train_attention_masks,\n","                                  mask_ids=train_mask_ids,\n","                                  y=y[0])\n","train_loader_mask = DataLoader(dataset=train_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","valid_dataset_mask = Dataset_Mask(input_ids=valid_input_ids,\n","                                  token_type_ids=valid_token_type_ids,\n","                                  attention_masks=valid_attention_masks,\n","                                  mask_ids=valid_mask_ids,\n","                                  y=y[1])\n","valid_loader_mask = DataLoader(dataset=valid_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","print(\"start traing......\")\n","training_mask(model=model,\n","              epoch=epochs,\n","              train=train_loader_mask,\n","              valid=valid_loader_mask,\n","              quote_tensor=quote_embeddings,\n","              device=device)\n","\n","\n"],"metadata":{"id":"AzcwnWag0ugn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670752373638,"user_tz":-540,"elapsed":472070,"user":{"displayName":"bertenglish sememe","userId":"09784491746436435551"}},"outputId":"db38ba78-c1ae-49d0-e6cc-65b5f5f65c88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading train and valid dataloader ...\n","start traing......\n","Epoch:  1\n","Epoch running time :47\n","Train | Loss:2602.949 MRR: 0.198 NDCG: 0.195\n","Valid | Loss:2875.30056 MRR: 0.156 NDCG: 0.155\n","Epoch:  2\n","Epoch running time :47\n","Train | Loss:1501.078 MRR: 0.493 NDCG: 0.513\n","Valid | Loss:3007.19924 MRR: 0.166 NDCG: 0.162\n","Epoch:  3\n","Epoch running time :47\n","Train | Loss:686.266 MRR: 0.776 NDCG: 0.797\n","Valid | Loss:3209.77192 MRR: 0.166 NDCG: 0.161\n","Epoch:  4\n","Epoch running time :47\n","Train | Loss:315.102 MRR: 0.912 NDCG: 0.926\n","Valid | Loss:3271.31366 MRR: 0.176 NDCG: 0.174\n","Epoch:  5\n","Epoch running time :47\n","Train | Loss:161.241 MRR: 0.965 NDCG: 0.973\n","Valid | Loss:3341.56463 MRR: 0.184 NDCG: 0.181\n","Epoch:  6\n","Epoch running time :48\n","Train | Loss:75.269 MRR: 0.986 NDCG: 0.989\n","Valid | Loss:3390.82686 MRR: 0.178 NDCG: 0.173\n","Epoch:  7\n","Epoch running time :47\n","Train | Loss:56.477 MRR: 0.994 NDCG: 0.995\n","Valid | Loss:3418.99340 MRR: 0.177 NDCG: 0.172\n","Epoch:  8\n","Epoch running time :47\n","Train | Loss:45.128 MRR: 0.993 NDCG: 0.995\n","Valid | Loss:3455.06925 MRR: 0.179 NDCG: 0.178\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, quote_tensor, device):\n","    model.eval()\n","    t_batch = len(test_loader)\n","    criterion = nn.CrossEntropyLoss()\n","    quote_tensor = quote_tensor.to(device)\n","    with torch.no_grad():\n","        total_loss, total_MRR, total_NDCG, total_ranks = 0, 0, 0, 0\n","        total_recalls = [0, 0, 0, 0, 0, 0, 0]\n","        all_ranks = []\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            \n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            \n","            ranks = rank_gold(outputs, labels)\n","            all_ranks += ranks\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            recalls = recall(outputs, labels)\n","            \n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","            total_ranks += np.sum(ranks)\n","            total_recalls = [x + y for x, y in zip(total_recalls, recalls)]\n","\n","        total_recalls = [element / len(y[2]) for element in total_recalls]\n","\n","        print(\n","            \"Test | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f} Mean Rank: {:.0f} Median Rank: {:.0f} Variance: {:.0f}\"\n","            .format(total_loss, total_MRR / t_batch,\n","                    total_NDCG / t_batch, np.mean(all_ranks),\n","                    np.median(all_ranks)+1,\n","                    np.std(all_ranks)))\n","        print(\"Recall@[1,3,5,10,20,30,100]: \" + str(total_recalls))\n","        \n","\n","test_input_ids, test_token_type_ids, test_attention_masks, test_mask_ids = make_context_tensors(tests[0], tests[2])\n","test_dataset_mask = Dataset_Mask(input_ids=test_input_ids,\n","                                 token_type_ids=test_token_type_ids,\n","                                 attention_masks=test_attention_masks,\n","                                 mask_ids=test_mask_ids,\n","                                 y=y[2])\n","test_loader_mask = DataLoader(dataset=test_dataset_mask,\n","                              batch_size=batch,\n","                              num_workers=2)\n","\n","model = torch.load('/content/drive/MyDrive/model/model_english.model')\n","model.to(device)\n","test(model=model,\n","     test_loader=test_loader_mask,\n","     quote_tensor=quote_embeddings,\n","     device=device)"],"metadata":{"id":"ZylzIhs3oNp-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670752392087,"user_tz":-540,"elapsed":18451,"user":{"displayName":"bertenglish sememe","userId":"09784491746436435551"}},"outputId":"82a429f8-a071-4ed6-9ce3-a58f8b25ceef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test | Loss:3453.06718 MRR: 0.182 NDCG: 0.179 Mean Rank: 200 Median Rank: 62 Variance: 303\n","Recall@[1,3,5,10,20,30,100]: [0.124, 0.192, 0.23, 0.292, 0.362, 0.405, 0.58]\n"]}]}]}