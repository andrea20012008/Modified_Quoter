{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"efe8a9aa07e04e6fbc8013a965aece51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9a0979e07224e0ba1c85f0b77cc249c","IPY_MODEL_418cdf4b49e44f6ca690ee3494513839","IPY_MODEL_10212b21cf364e78821b49c37cd22ce9"],"layout":"IPY_MODEL_219d114cbedf40b2bd6adc280cdb0d64"}},"c9a0979e07224e0ba1c85f0b77cc249c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35f6e1ee6b40418f96c2d898bf73be5e","placeholder":"​","style":"IPY_MODEL_d9fd1ae71391472ca508030c9da5090a","value":" 10%"}},"418cdf4b49e44f6ca690ee3494513839":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbebdee568624cf585bb9ef51dba3187","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7df8be1ac7eb42aea1af60a3ce933be7","value":4}},"10212b21cf364e78821b49c37cd22ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a4c5260920481f8b542e20b71f84eb","placeholder":"​","style":"IPY_MODEL_a662620936f546098448cb3ac6c21dd2","value":" 4/40 [33:26&lt;4:00:34, 400.95s/it]"}},"219d114cbedf40b2bd6adc280cdb0d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f6e1ee6b40418f96c2d898bf73be5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9fd1ae71391472ca508030c9da5090a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbebdee568624cf585bb9ef51dba3187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7df8be1ac7eb42aea1af60a3ce933be7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9a4c5260920481f8b542e20b71f84eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a662620936f546098448cb3ac6c21dd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7EyPuqydrUE","executionInfo":{"status":"ok","timestamp":1670731460908,"user_tz":-540,"elapsed":3313,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"1278315d-c269-45fa-bb83-f5252f57eda4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers==3.0.2\n","!pip install OpenHowNet==0.0.1a11\n","!pip install nltk==3.5\n","#import transformers1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tGUB7jCfNrG","executionInfo":{"status":"ok","timestamp":1670730916849,"user_tz":-540,"elapsed":28028,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"13527d49-d68c-4fcb-fbdd-196acdde3a45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 20.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 61.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 69.2 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 32.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=80f34698386f743480416d15266585b8204acb318c1dc2dcc6b555032bfd12f0\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting OpenHowNet==0.0.1a11\n","  Downloading OpenHowNet-0.0.1a11-py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (4.64.1)\n","Collecting anytree\n","  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 621 kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from anytree->OpenHowNet==0.0.1a11) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2022.9.24)\n","Installing collected packages: anytree, OpenHowNet\n","Successfully installed OpenHowNet-0.0.1a11 anytree-2.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.5\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (4.64.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434692 sha256=93cae0cc6e04e69ac6bcf28f712e6514a65d2e824fdadc94c34e1f9493f425dc\n","  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed nltk-3.5\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertModel, AdamW, BertSememeModel\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import os\n","import time\n","import random\n","from sklearn.metrics import accuracy_score\n","import numpy as np"],"metadata":{"id":"Sb8bfoRhfQzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(42)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch = 2\n","sample_num = 19\n","learning_rate = 3e-5\n","epochs = 40\n","max_length = 80"],"metadata":{"id":"APW9_8Bdd4by"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(path):\n","    with open(path, 'r', encoding='utf-8') as f:\n","        former, middle, latter = [], [], []\n","\n","        lines = f.readlines()\n","        for line in lines:\n","            line = line.strip().lower().split('\\t')\n","            former.append(line[0])\n","            middle.append(line[1])\n","            latter.append(line[2])\n","        \n","        train_former, valid_former, test_former = former[:1000], former[1000:2000], former[2000:3000]\n","        train_middle, valid_middle, test_middle = middle[:1000], middle[1000:2000], middle[2000:3000]\n","        train_latter, valid_latter, test_latter = latter[:1000], latter[1000:2000], latter[2000:3000]\n","\n","    all_quotes = train_middle + valid_middle + test_middle\n","    all_quotes = sorted(list(set(all_quotes)))\n","\n","    y_train = [all_quotes.index(q) for q in train_middle]\n","    y_valid = [all_quotes.index(q) for q in valid_middle]\n","    y_test = [all_quotes.index(q) for q in test_middle]\n","\n","    trains = [train_former, train_middle, train_latter]\n","    valids = [valid_former, valid_middle, valid_latter]\n","    tests = [test_former, test_middle, test_latter]\n","    y = [torch.LongTensor(y_train), torch.LongTensor(y_valid), torch.LongTensor(y_test)]\n","\n","    return trains, valids, tests, y , all_quotes"],"metadata":{"id":"4tDLcHlLd8yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/quoter/data/modern_chinese.txt\"\n","trains, valids, tests, y, all_quotes = load_data(data_path)\n","\n","# get the Tokenizer used for pretraining model\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"],"metadata":{"id":"Z2ngFzPXeARp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from the source code\n","def make_context_tensors(former, latter):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","    mask_ids = []\n","    for f, l in zip(former, latter):\n","        sent = f + \"[MASK]\" + l\n","        encoded_dict = tokenizer.encode_plus(sent,\n","                                             add_special_tokens=True,\n","                                             max_length=150,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict['token_type_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        mask_index = encoded_dict['input_ids'][0].tolist().index(103)\n","        mask_ids.append(mask_index)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    return input_ids, token_type_ids, attention_masks, torch.LongTensor(mask_ids)"],"metadata":{"id":"JlUMs3IkeF_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_input_ids, train_token_type_ids, train_attention_masks, train_mask_ids = make_context_tensors(trains[0], trains[2])\n","valid_input_ids, valid_token_type_ids, valid_attention_masks, valid_mask_ids = make_context_tensors(valids[0], valids[2])"],"metadata":{"id":"RTokzvBZQACa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from source code\n","class Dataset(Dataset):\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 quote):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.quote = quote\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.quote is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.quote[\n","                idx]\n","\n","\n","train_dataset = Dataset(input_ids=train_input_ids,\n","                        token_type_ids=train_token_type_ids,\n","                        attention_masks=train_attention_masks,\n","                        mask_ids=train_mask_ids,\n","                        quote=trains[1])\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n","valid_dataset = Dataset(input_ids=valid_input_ids,\n","                        token_type_ids=valid_token_type_ids,\n","                        attention_masks=valid_attention_masks,\n","                        mask_ids=valid_mask_ids,\n","                        quote=valids[1])\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n"],"metadata":{"id":"yNt4kqlWeOWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_quotes(quote, num):\n","    quotes_selcet = all_quotes[:]\n","    quotes_selcet.remove(quote)\n","    quotes = random.sample(quotes_selcet, num)\n","    quotes.append(quote)\n","    random.shuffle(quotes)\n","    return quotes\n","\n","# Obtained directly from the source code\n","def make_quote_tensors(quote):\n","    quotes = generate_quotes(quote, num=sample_num)\n","    label = quotes.index(quote)\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)  # [num, 80]\n","    quote_ids = torch.LongTensor([all_quotes.index(q) for q in quotes])\n","    return input_ids, label, quote_ids\n"],"metadata":{"id":"mSQOsfcSTM9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Context_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, context_input_ids, context_token_type_ids, context_attention_masks, mask_ids):\n","        outputs = self.bert_model(input_ids=context_input_ids,\n","                                  token_type_ids=context_token_type_ids,\n","                                  attention_mask=context_attention_masks)\n","        \n","        last_hidden_state = outputs[0]\n","        all_context = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            mask = self.dropout(mask)\n","            context = mask.unsqueeze(dim=0)\n","            all_context.append(context)\n","\n","        return torch.cat(all_context, dim=0)\n","\n","\n","class Quote_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertSememeModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        #self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        # self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, quotes):\n","        quote_tensor = []\n","        labels = []\n","        for quote in quotes:\n","            quote_input_ids, label, quote_ids = make_quote_tensors(quote)\n","            quote_input_ids = quote_input_ids.to(device)\n","            quote_ids = quote_ids.to(device)\n","            outputs = self.bert_model(input_ids=quote_input_ids)\n","            output = torch.mean(outputs[0], dim=1)\n","            \n","            quote_tensor.append(output)\n","            labels.append(label)\n","        quote_tensor = torch.stack(quote_tensor, dim=0)\n","        return quote_tensor, labels\n","\n","\n","class QuotRec_Net(nn.Module):\n","    def __init__(self, context_model, quote_model):\n","        super().__init__()\n","        self.context_model = context_model\n","        self.quote_model = quote_model\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                quotes):\n","        context_output = self.context_model(input_ids, token_type_ids,\n","                                           attention_masks, mask_ids)\n","        context_output = context_output.unsqueeze(dim=1)\n","\n","        quote_output, labels = self.quote_model(quotes)\n","        quote_output = quote_output.permute(0, 2, 1)\n","\n","        outputs = torch.matmul(context_output, quote_output).squeeze(dim=1)\n","        return outputs, torch.LongTensor(labels)\n","\n","context_model = Context_Encoder()\n","quote_model = Quote_Encoder()\n","model = QuotRec_Net(context_model, quote_model)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYFi7GbKeWsN","executionInfo":{"status":"ok","timestamp":1670731556601,"user_tz":-540,"elapsed":19490,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"8eb7f682-fc99-4b0d-dc10-43930b7e6a71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:transformers.modeling_utils:Some weights of BertSememeModel were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['bert.embeddings.sememe_embeddings.lut.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["QuotRec_Net(\n","  (context_model): Context_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (quote_model): Quote_Encoder(\n","    (bert_model): BertSememeModel(\n","      (embeddings): BertSememeEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (sememe_embeddings): SememeEmbeddings(\n","          (lut): Embedding(2187, 768)\n","        )\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import math\n","import tqdm.notebook as tq\n","def training(model, epoch, train, valid, device):\n","\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_acc = 0\n","    best_loss = math.inf\n","    losses = []\n","    count = 0\n","\n","    for epoch in tq.tqdm(range(epoch)):\n","        start = time.perf_counter()\n","        total_loss, total_acc = 0, 0\n","        print(\"Epoch: \", epoch + 1)\n","\n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs, labels = model(input_ids, token_type_ids, attention_masks,mask_ids, quotes)\n","            labels = labels.to(device, dtype=torch.long)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, pred = torch.max(outputs.cpu().data, 1)\n","            acc = accuracy_score(pred, labels.cpu())\n","            total_loss += loss.item()\n","            total_acc += acc\n","        print('Train | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_train))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","\n","                outputs, labels = model(input_ids, token_type_ids,attention_masks, mask_ids, quotes)\n","                labels = labels.to(device, dtype=torch.long)\n","                loss = criterion(outputs, labels)\n","                _, pred = torch.max(outputs.cpu().data, 1)\n","\n","                acc = accuracy_score(pred, labels.cpu())\n","                total_loss += loss.item()\n","                total_acc += acc\n","            losses.append(total_loss)\n","            print('Valid | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_valid))\n","\n","            if total_acc >= best_acc and total_loss <= best_loss:\n","                best_acc = total_acc\n","                best_loss = total_loss\n","                if not os.path.exists(\"./model\"):\n","                    os.mkdir(\"./model\")\n","                torch.save(model.quote_model.state_dict(), \"/content/drive/MyDrive/model/modern_chinese_quote.pth\")\n","                torch.save(model.context_model.state_dict(), \"/content/drive/MyDrive/model/modern_chinese_context.pth\")\n","                count = 0\n","            elif total_loss > best_loss:\n","                count += 1\n","\n","        end = time.perf_counter()\n","\n","        if count == 3:\n","            print(\"Early Stopping\")\n","            break\n","\n","\n","training(model=model,\n","         epoch=epochs,\n","         train=train_loader,\n","         valid=valid_loader,\n","         device=device)\n","\n","\n","def make_tensors(quotes):\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)\n","    return input_ids\n","\n","\n","quote_input_ids = make_tensors(all_quotes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335,"referenced_widgets":["efe8a9aa07e04e6fbc8013a965aece51","c9a0979e07224e0ba1c85f0b77cc249c","418cdf4b49e44f6ca690ee3494513839","10212b21cf364e78821b49c37cd22ce9","219d114cbedf40b2bd6adc280cdb0d64","35f6e1ee6b40418f96c2d898bf73be5e","d9fd1ae71391472ca508030c9da5090a","fbebdee568624cf585bb9ef51dba3187","7df8be1ac7eb42aea1af60a3ce933be7","f9a4c5260920481f8b542e20b71f84eb","a662620936f546098448cb3ac6c21dd2"]},"id":"mlczWb0UeeQ2","outputId":"6dfe7f52-1b9c-414a-8bb9-3c64613d8f79","executionInfo":{"status":"ok","timestamp":1670735110364,"user_tz":-540,"elapsed":2007293,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe8a9aa07e04e6fbc8013a965aece51"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch:  1\n","Train | Loss:1120.10286 Acc:0.335\n","Valid | Loss:1127.82479 Acc:0.402\n","Epoch:  2\n","Train | Loss:789.08613 Acc:0.534\n","Valid | Loss:1038.74296 Acc:0.424\n","Epoch:  3\n","Train | Loss:516.63204 Acc:0.687\n","Valid | Loss:1281.50861 Acc:0.385\n","Epoch:  4\n","Train | Loss:339.04292 Acc:0.789\n","Valid | Loss:1389.68664 Acc:0.439\n","Epoch:  5\n","Train | Loss:303.00448 Acc:0.827\n","Valid | Loss:1505.68285 Acc:0.432\n","Early Stopping\n"]}]},{"cell_type":"code","source":["# Generate sentence vector for quotes\n","quote_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","model_dict = quote_model.state_dict()\n","save_model_state = torch.load(\"/content/drive/MyDrive/model/modern_chinese_quote.pth\")\n","\n","state_dict = {k[11:]: v for k, v in save_model_state.items() if k[11:] in model_dict.keys()}\n","model_dict.update(state_dict)\n","quote_model.load_state_dict(model_dict)\n","\n","quote_model = quote_model.to(device)\n","quote_input_ids = quote_input_ids.to(device)\n","\n","quote_embeddings = []\n","quote_model.eval()\n","\n","with torch.no_grad():\n","    for input_ids in quote_input_ids:\n","        input_ids = input_ids.unsqueeze(dim=0)\n","        outputs = quote_model(input_ids=input_ids)\n","        quote_tensor = torch.mean(outputs[0], dim=1)\n","        quote_embeddings.append(quote_tensor)\n","    quote_embeddings = torch.cat(quote_embeddings, dim=0)\n"],"metadata":{"id":"BgODzAlUelT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the mask method for training\n","class QuotRecNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks,\n","                mask_ids, quote_tensor):\n","        outputs = self.bert_model(input_ids=input_ids,\n","                                  token_type_ids=token_type_ids,\n","                                  attention_mask=attention_masks)\n","        last_hidden_state = outputs[0]\n","        all_outputs = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            context = self.dropout(mask)\n","            context = context.unsqueeze(dim=0)\n","            output = torch.mm(context, quote_tensor.t())\n","            all_outputs.append(output)\n","        all_outputs = torch.cat(all_outputs, dim=0)\n","        return all_outputs\n","\n","\n","model = QuotRecNet()\n","model.to(device)\n"],"metadata":{"id":"P82Gpy9MTjVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670736147703,"user_tz":-540,"elapsed":4282,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"d323ba95-7123-4ee4-b976-07727b646b01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRecNet(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Evaluation Metrics\n","# Rank\n","def rank_gold(predicts, golds):\n","  ranks = []\n","  ps = predicts.data.cpu().numpy()\n","  gs = golds.cpu().numpy()\n","  for i in range(len(ps)):\n","    predict = ps[i]\n","    gold_index = gs[i]\n","    predict_value = predict[gold_index]\n","    predict_sort = sorted(predict, reverse=True)\n","    predict_index = predict_sort.index(predict_value)\n","    if predict_index == -1:\n","        break\n","    ranks.append(predict_index)\n","  return ranks\n","\n","\n","# NDCG@5\n","def get_NDCG(ranks):\n","    total = 0.0\n","    for r in ranks:\n","        if r < 5:  # k=5\n","            total += 1.0 / np.log2(r + 2)\n","    return total / len(ranks)\n","\n","\n","# get recall@k\n","def recall(predicts, golds):\n","    predicts = predicts.data.cpu().numpy()\n","    golds = list(golds)\n","    predicts_index = list(np.argsort(-predicts, axis=1))\n","    predicts_index = [list(element) for element in predicts_index]\n","    recall_values = [0, 0, 0, 0, 0, 0, 0] # 1, 3, 5, 10, 20, 30, 100, 300, 500\n","    recalls = [1, 3, 5, 10, 20, 30, 100]\n","\n","    for i in range(len(golds)):\n","        gold_value_index = predicts_index[i].index(golds[i])\n","        for val in range(len(recalls)):\n","            if gold_value_index < recalls[val]:\n","                recall_values[val] += 1\n","\n","    return recall_values\n","\n","def get_mrr(ranks):\n","    return np.average([1.0 / (r + 1) for r in ranks])"],"metadata":{"id":"4OvvDjTWe0ke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training_mask(model, epoch, train, valid, quote_tensor, device):\n","    learning_rate = 3e-5\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_MRR = 0\n","    count = 0\n","    quote_tensor = quote_tensor.to(device)\n","    for epoch in range(epoch):\n","        start = time.perf_counter()\n","        print(\"Epoch: \", epoch + 1)\n","        total_loss, total_MRR, total_NDCG = 0, 0, 0\n","        \n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","  \n","            ranks = rank_gold(outputs, labels)\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","        end = time.perf_counter()\n","        print('Epoch running time :{:.0f}'.format(end - start))\n","        print('Train | Loss:{:.3f} MRR: {:.3f} NDCG: {:.3f}'.format(total_loss, total_MRR/len_train, total_NDCG/len_train))\n","\n","        # validation\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_MRR, total_NDCG = 0, 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.long)\n","                outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","                loss = criterion(outputs, labels)\n","                \n","                ranks = rank_gold(outputs, labels)\n","                MRR = get_mrr(ranks)\n","                NDCG = get_NDCG(ranks)\n","                \n","                total_loss += loss.item()\n","                total_MRR += MRR\n","                total_NDCG += NDCG\n","            print(\"Valid | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f}\".format(total_loss, total_MRR / len_valid,total_NDCG / len_valid))\n","        \n","        if total_MRR > best_MRR:\n","            best_MRR = total_MRR\n","            torch.save(model, \"/content/drive/MyDrive/model/model_modern_chinese.model\")\n","            count = 0\n","        else:\n","            learning_rate = learning_rate * 0.9\n","            count += 1\n","        \n","        # Early Stopping\n","        if count == 3:\n","            break"],"metadata":{"id":"ndwGb997fFVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask Dataset and DataLoader\n","class Dataset_Mask(Dataset):\n","\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 y):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.label = y\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.label[\n","                idx]\n","\n","\n","print(\"loading train and valid dataloader ...\")\n","train_dataset_mask = Dataset_Mask(input_ids=train_input_ids,\n","                                  token_type_ids=train_token_type_ids,\n","                                  attention_masks=train_attention_masks,\n","                                  mask_ids=train_mask_ids,\n","                                  y=y[0])\n","train_loader_mask = DataLoader(dataset=train_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","valid_dataset_mask = Dataset_Mask(input_ids=valid_input_ids,\n","                                  token_type_ids=valid_token_type_ids,\n","                                  attention_masks=valid_attention_masks,\n","                                  mask_ids=valid_mask_ids,\n","                                  y=y[1])\n","valid_loader_mask = DataLoader(dataset=valid_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","print(\"start traing......\")\n","training_mask(model=model,\n","              epoch=epochs,\n","              train=train_loader_mask,\n","              valid=valid_loader_mask,\n","              quote_tensor=quote_embeddings,\n","              device=device)"],"metadata":{"id":"EMMwKZXYe5mG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670737055220,"user_tz":-540,"elapsed":734079,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"17a1a488-d23f-466c-85dc-ddf404d45e28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading train and valid dataloader ...\n","start traing......\n","Epoch:  1\n","Epoch running time :45\n","Train | Loss:2376.683 MRR: 0.229 NDCG: 0.231\n","Valid | Loss:2765.51097 MRR: 0.185 NDCG: 0.185\n","Epoch:  2\n","Epoch running time :45\n","Train | Loss:1403.334 MRR: 0.521 NDCG: 0.543\n","Valid | Loss:2608.93168 MRR: 0.244 NDCG: 0.245\n","Epoch:  3\n","Epoch running time :45\n","Train | Loss:797.376 MRR: 0.755 NDCG: 0.778\n","Valid | Loss:2687.81166 MRR: 0.244 NDCG: 0.241\n","Epoch:  4\n","Epoch running time :45\n","Train | Loss:463.578 MRR: 0.887 NDCG: 0.902\n","Valid | Loss:2664.60437 MRR: 0.265 NDCG: 0.268\n","Epoch:  5\n","Epoch running time :45\n","Train | Loss:308.447 MRR: 0.936 NDCG: 0.947\n","Valid | Loss:2646.29110 MRR: 0.266 NDCG: 0.266\n","Epoch:  6\n","Epoch running time :45\n","Train | Loss:205.262 MRR: 0.968 NDCG: 0.976\n","Valid | Loss:2688.18826 MRR: 0.266 NDCG: 0.267\n","Epoch:  7\n","Epoch running time :45\n","Train | Loss:136.756 MRR: 0.985 NDCG: 0.989\n","Valid | Loss:2685.19742 MRR: 0.277 NDCG: 0.277\n","Epoch:  8\n","Epoch running time :45\n","Train | Loss:103.008 MRR: 0.986 NDCG: 0.989\n","Valid | Loss:2686.85102 MRR: 0.279 NDCG: 0.278\n","Epoch:  9\n","Epoch running time :45\n","Train | Loss:77.285 MRR: 0.992 NDCG: 0.994\n","Valid | Loss:2725.36739 MRR: 0.270 NDCG: 0.269\n","Epoch:  10\n","Epoch running time :45\n","Train | Loss:71.858 MRR: 0.995 NDCG: 0.996\n","Valid | Loss:2702.19136 MRR: 0.282 NDCG: 0.278\n","Epoch:  11\n","Epoch running time :45\n","Train | Loss:64.502 MRR: 0.996 NDCG: 0.997\n","Valid | Loss:2773.30156 MRR: 0.278 NDCG: 0.278\n","Epoch:  12\n","Epoch running time :45\n","Train | Loss:59.073 MRR: 0.997 NDCG: 0.998\n","Valid | Loss:2835.52819 MRR: 0.276 NDCG: 0.273\n","Epoch:  13\n","Epoch running time :45\n","Train | Loss:46.737 MRR: 0.997 NDCG: 0.998\n","Valid | Loss:2803.02400 MRR: 0.272 NDCG: 0.272\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, quote_tensor, device):\n","    model.eval()\n","    t_batch = len(test_loader)\n","    criterion = nn.CrossEntropyLoss()\n","    quote_tensor = quote_tensor.to(device)\n","    with torch.no_grad():\n","        total_loss, total_MRR, total_NDCG, total_ranks = 0, 0, 0, 0\n","        total_recalls = [0, 0, 0, 0, 0, 0, 0]\n","        all_ranks = []\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            \n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            \n","            ranks = rank_gold(outputs, labels)\n","            all_ranks += ranks\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            recalls = recall(outputs, labels)\n","            \n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","            total_ranks += np.sum(ranks)\n","            total_recalls = [x + y for x, y in zip(total_recalls, recalls)]\n","\n","        total_recalls = [element / len(y[2]) for element in total_recalls]\n","\n","        print(\n","            \"Test | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f} Mean Rank: {:.0f} Median Rank: {:.0f} Variance: {:.0f}\"\n","            .format(total_loss, total_MRR / t_batch,\n","                    total_NDCG / t_batch, np.mean(all_ranks),\n","                    np.median(all_ranks)+1,\n","                    np.std(all_ranks)))\n","        print(\"Recall@[1,3,5,10,20,30,100]: \" + str(total_recalls))\n","        \n","\n","test_input_ids, test_token_type_ids, test_attention_masks, test_mask_ids = make_context_tensors(tests[0], tests[2])\n","test_dataset_mask = Dataset_Mask(input_ids=test_input_ids,\n","                                 token_type_ids=test_token_type_ids,\n","                                 attention_masks=test_attention_masks,\n","                                 mask_ids=test_mask_ids,\n","                                 y=y[2])\n","test_loader_mask = DataLoader(dataset=test_dataset_mask,\n","                              batch_size=batch,\n","                              num_workers=2)\n","\n","model = torch.load('/content/drive/MyDrive/model/model_modern_chinese.model')\n","model.to(device)\n","test(model=model,\n","     test_loader=test_loader_mask,\n","     quote_tensor=quote_embeddings,\n","     device=device)"],"metadata":{"id":"w_WTyan4fBLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670737120232,"user_tz":-540,"elapsed":16093,"user":{"displayName":"ModernChin Sememe","userId":"16484441608516656904"}},"outputId":"f10df5b3-615e-4a4a-b132-35819e1cc7c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test | Loss:2790.86053 MRR: 0.273 NDCG: 0.275 Mean Rank: 143 Median Rank: 30 Variance: 227\n","Recall@[1,3,5,10,20,30,100]: [0.208, 0.304, 0.333, 0.391, 0.444, 0.503, 0.656]\n"]}]}]}