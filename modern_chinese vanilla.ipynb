{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"3992149393184450b77d5a8070c74c8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd02cf5f043840afb90ebe7f1ecbf14d","IPY_MODEL_ed8b8ee0563040b383f3d56b1648cd98","IPY_MODEL_b4507bf2dde5421799e2959c96adaeef"],"layout":"IPY_MODEL_71dc9d5a1e0046d69d2ebe6346a89c92"}},"bd02cf5f043840afb90ebe7f1ecbf14d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e884e65dd8744e8b40ec3130d449d7d","placeholder":"​","style":"IPY_MODEL_5416274a4c9f4583ba5f6dbea29b658c","value":"  8%"}},"ed8b8ee0563040b383f3d56b1648cd98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d651edcaac642c48d75ced88ad11d02","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be0163116d4844929615b196b38dcc9c","value":3}},"b4507bf2dde5421799e2959c96adaeef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccc2896081f64463b086f8f15514305d","placeholder":"​","style":"IPY_MODEL_58513846b6d54d14b260f28f22f870ef","value":" 3/40 [26:10&lt;4:02:06, 392.61s/it]"}},"71dc9d5a1e0046d69d2ebe6346a89c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e884e65dd8744e8b40ec3130d449d7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5416274a4c9f4583ba5f6dbea29b658c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d651edcaac642c48d75ced88ad11d02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be0163116d4844929615b196b38dcc9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccc2896081f64463b086f8f15514305d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58513846b6d54d14b260f28f22f870ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7EyPuqydrUE","executionInfo":{"status":"ok","timestamp":1670735735564,"user_tz":-540,"elapsed":2739,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"81d876bd-bc12-4aa0-98bc-ff77a554503a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers==3.0.2\n","!pip install OpenHowNet==0.0.1a11\n","!pip install nltk==3.5\n","#import transformers1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tGUB7jCfNrG","executionInfo":{"status":"ok","timestamp":1670735746459,"user_tz":-540,"elapsed":8681,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"1ae021a9-1b72-4f8a-8a4e-f7e25d83c9a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.8/dist-packages (3.0.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (0.0.53)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (0.1.97)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: OpenHowNet==0.0.1a11 in /usr/local/lib/python3.8/dist-packages (0.0.1a11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.23.0)\n","Requirement already satisfied: anytree in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from OpenHowNet==0.0.1a11) (4.64.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from anytree->OpenHowNet==0.0.1a11) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->OpenHowNet==0.0.1a11) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.8/dist-packages (3.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (4.64.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertModel, AdamW\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import os\n","import time\n","import random\n","from sklearn.metrics import accuracy_score\n","import numpy as np"],"metadata":{"id":"Sb8bfoRhfQzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(42)\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch = 2\n","sample_num = 19\n","learning_rate = 3e-5\n","epochs = 40\n","max_length = 80"],"metadata":{"id":"APW9_8Bdd4by"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(path):\n","    with open(path, 'r', encoding='utf-8') as f:\n","        former, middle, latter = [], [], []\n","\n","        lines = f.readlines()\n","        for line in lines:\n","            line = line.strip().lower().split('\\t')\n","            former.append(line[0])\n","            middle.append(line[1])\n","            latter.append(line[2])\n","        \n","        train_former, valid_former, test_former = former[:1000], former[1000:2000], former[2000:3000]\n","        train_middle, valid_middle, test_middle = middle[:1000], middle[1000:2000], middle[2000:3000]\n","        train_latter, valid_latter, test_latter = latter[:1000], latter[1000:2000], latter[2000:3000]\n","\n","    all_quotes = train_middle + valid_middle + test_middle\n","    all_quotes = sorted(list(set(all_quotes)))\n","\n","    y_train = [all_quotes.index(q) for q in train_middle]\n","    y_valid = [all_quotes.index(q) for q in valid_middle]\n","    y_test = [all_quotes.index(q) for q in test_middle]\n","\n","    trains = [train_former, train_middle, train_latter]\n","    valids = [valid_former, valid_middle, valid_latter]\n","    tests = [test_former, test_middle, test_latter]\n","    y = [torch.LongTensor(y_train), torch.LongTensor(y_valid), torch.LongTensor(y_test)]\n","\n","    return trains, valids, tests, y , all_quotes"],"metadata":{"id":"4tDLcHlLd8yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/quoter/data/modern_chinese.txt\"\n","trains, valids, tests, y, all_quotes = load_data(data_path)\n","\n","# get the Tokenizer used for pretraining model\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n"],"metadata":{"id":"Z2ngFzPXeARp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from the source code\n","def make_context_tensors(former, latter):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","    mask_ids = []\n","    for f, l in zip(former, latter):\n","        sent = f + \"[MASK]\" + l\n","        encoded_dict = tokenizer.encode_plus(sent,\n","                                             add_special_tokens=True,\n","                                             max_length=150,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_attention_mask=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict['token_type_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","        mask_index = encoded_dict['input_ids'][0].tolist().index(103)\n","        mask_ids.append(mask_index)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    return input_ids, token_type_ids, attention_masks, torch.LongTensor(mask_ids)"],"metadata":{"id":"JlUMs3IkeF_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_input_ids, train_token_type_ids, train_attention_masks, train_mask_ids = make_context_tensors(trains[0], trains[2])\n","valid_input_ids, valid_token_type_ids, valid_attention_masks, valid_mask_ids = make_context_tensors(valids[0], valids[2])"],"metadata":{"id":"RTokzvBZQACa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obtained directly from source code\n","class Dataset(Dataset):\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 quote):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.quote = quote\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.quote is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.quote[\n","                idx]\n","\n","\n","train_dataset = Dataset(input_ids=train_input_ids,\n","                        token_type_ids=train_token_type_ids,\n","                        attention_masks=train_attention_masks,\n","                        mask_ids=train_mask_ids,\n","                        quote=trains[1])\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n","valid_dataset = Dataset(input_ids=valid_input_ids,\n","                        token_type_ids=valid_token_type_ids,\n","                        attention_masks=valid_attention_masks,\n","                        mask_ids=valid_mask_ids,\n","                        quote=valids[1])\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=batch,\n","                          shuffle=True,\n","                          num_workers=2)\n"],"metadata":{"id":"yNt4kqlWeOWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_quotes(quote, num):\n","    quotes_selcet = all_quotes[:]\n","    quotes_selcet.remove(quote)\n","    quotes = random.sample(quotes_selcet, num)\n","    quotes.append(quote)\n","    random.shuffle(quotes)\n","    return quotes\n","\n","# Obtained directly from the source code\n","def make_quote_tensors(quote):\n","    quotes = generate_quotes(quote, num=sample_num)\n","    label = quotes.index(quote)\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)  # [num, 80]\n","    quote_ids = torch.LongTensor([all_quotes.index(q) for q in quotes])\n","    return input_ids, label, quote_ids\n"],"metadata":{"id":"mSQOsfcSTM9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Context_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, context_input_ids, context_token_type_ids, context_attention_masks, mask_ids):\n","        outputs = self.bert_model(input_ids=context_input_ids,\n","                                  token_type_ids=context_token_type_ids,\n","                                  attention_mask=context_attention_masks)\n","        \n","        last_hidden_state = outputs[0]\n","        all_context = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            mask = self.dropout(mask)\n","            context = mask.unsqueeze(dim=0)\n","            all_context.append(context)\n","\n","        return torch.cat(all_context, dim=0)\n","\n","\n","class Quote_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        #self.bert_model = BertSememeModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        # self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, quotes):\n","        quote_tensor = []\n","        labels = []\n","        for quote in quotes:\n","            quote_input_ids, label, quote_ids = make_quote_tensors(quote)\n","            quote_input_ids = quote_input_ids.to(device)\n","            quote_ids = quote_ids.to(device)\n","            outputs = self.bert_model(input_ids=quote_input_ids)\n","            output = torch.mean(outputs[0], dim=1)\n","            \n","            quote_tensor.append(output)\n","            labels.append(label)\n","        quote_tensor = torch.stack(quote_tensor, dim=0)\n","        return quote_tensor, labels\n","\n","\n","class QuotRec_Net(nn.Module):\n","    def __init__(self, context_model, quote_model):\n","        super().__init__()\n","        self.context_model = context_model\n","        self.quote_model = quote_model\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                quotes):\n","        context_output = self.context_model(input_ids, token_type_ids,\n","                                           attention_masks, mask_ids)\n","        context_output = context_output.unsqueeze(dim=1)\n","\n","        quote_output, labels = self.quote_model(quotes)\n","        quote_output = quote_output.permute(0, 2, 1)\n","\n","        outputs = torch.matmul(context_output, quote_output).squeeze(dim=1)\n","        return outputs, torch.LongTensor(labels)\n","\n","context_model = Context_Encoder()\n","quote_model = Quote_Encoder()\n","model = QuotRec_Net(context_model, quote_model)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYFi7GbKeWsN","executionInfo":{"status":"ok","timestamp":1670735791632,"user_tz":-540,"elapsed":9164,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"b2ba5526-6c78-4aac-fe85-c2181062aea3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRec_Net(\n","  (context_model): Context_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (quote_model): Quote_Encoder(\n","    (bert_model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import math\n","import tqdm.notebook as tq\n","def training(model, epoch, train, valid, device):\n","\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_acc = 0\n","    best_loss = math.inf\n","    losses = []\n","    count = 0\n","\n","    for epoch in tq.tqdm(range(epoch)):\n","        start = time.perf_counter()\n","        total_loss, total_acc = 0, 0\n","        print(\"Epoch: \", epoch + 1)\n","\n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs, labels = model(input_ids, token_type_ids, attention_masks,mask_ids, quotes)\n","            labels = labels.to(device, dtype=torch.long)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            _, pred = torch.max(outputs.cpu().data, 1)\n","            acc = accuracy_score(pred, labels.cpu())\n","            total_loss += loss.item()\n","            total_acc += acc\n","        print('Train | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_train))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_acc = 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, quotes) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","\n","                outputs, labels = model(input_ids, token_type_ids,attention_masks, mask_ids, quotes)\n","                labels = labels.to(device, dtype=torch.long)\n","                loss = criterion(outputs, labels)\n","                _, pred = torch.max(outputs.cpu().data, 1)\n","\n","                acc = accuracy_score(pred, labels.cpu())\n","                total_loss += loss.item()\n","                total_acc += acc\n","            losses.append(total_loss)\n","            print('Valid | Loss:{:.5f} Acc:{:.3f}'.format(total_loss, total_acc / len_valid))\n","\n","            if total_acc >= best_acc and total_loss <= best_loss:\n","                best_acc = total_acc\n","                best_loss = total_loss\n","                if not os.path.exists(\"./model\"):\n","                    os.mkdir(\"./model\")\n","                torch.save(model.quote_model.state_dict(), \"/content/drive/MyDrive/model/modern_chinese_quote.pth\")\n","                torch.save(model.context_model.state_dict(), \"/content/drive/MyDrive/model/modern_chinese_context.pth\")\n","                count = 0\n","            elif total_loss > best_loss:\n","                count += 1\n","\n","        end = time.perf_counter()\n","\n","        if count == 3:\n","            print(\"Early Stopping\")\n","            break\n","\n","\n","training(model=model,\n","         epoch=epochs,\n","         train=train_loader,\n","         valid=valid_loader,\n","         device=device)\n","\n","\n","def make_tensors(quotes):\n","    input_ids = []\n","    for q in quotes:\n","        encoded_dict = tokenizer.encode_plus(q,\n","                                             add_special_tokens=True,\n","                                             max_length=max_length,\n","                                             pad_to_max_length=True,\n","                                             truncation=True,\n","                                             return_tensors='pt')\n","        input_ids.append(encoded_dict['input_ids'])\n","    input_ids = torch.cat(input_ids, 0)\n","    return input_ids\n","\n","\n","quote_input_ids = make_tensors(all_quotes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["3992149393184450b77d5a8070c74c8d","bd02cf5f043840afb90ebe7f1ecbf14d","ed8b8ee0563040b383f3d56b1648cd98","b4507bf2dde5421799e2959c96adaeef","71dc9d5a1e0046d69d2ebe6346a89c92","0e884e65dd8744e8b40ec3130d449d7d","5416274a4c9f4583ba5f6dbea29b658c","6d651edcaac642c48d75ced88ad11d02","be0163116d4844929615b196b38dcc9c","ccc2896081f64463b086f8f15514305d","58513846b6d54d14b260f28f22f870ef"]},"id":"mlczWb0UeeQ2","executionInfo":{"status":"ok","timestamp":1670732331378,"user_tz":-540,"elapsed":1571579,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"c4f962cd-37ed-4fd1-eaf2-ff72100a2817"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3992149393184450b77d5a8070c74c8d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch:  1\n","Train | Loss:1035.76084 Acc:0.408\n","Valid | Loss:1216.02518 Acc:0.401\n","Epoch:  2\n","Train | Loss:683.47158 Acc:0.599\n","Valid | Loss:1332.98398 Acc:0.378\n","Epoch:  3\n","Train | Loss:438.61304 Acc:0.723\n","Valid | Loss:1429.74338 Acc:0.431\n","Epoch:  4\n","Train | Loss:326.72613 Acc:0.806\n","Valid | Loss:1750.57805 Acc:0.388\n","Early Stopping\n"]}]},{"cell_type":"code","source":["# Generate sentence vector for quotes\n","quote_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","model_dict = quote_model.state_dict()\n","save_model_state = torch.load(\"/content/drive/MyDrive/model/modern_chinese_quote.pth\")\n","\n","state_dict = {k[11:]: v for k, v in save_model_state.items() if k[11:] in model_dict.keys()}\n","model_dict.update(state_dict)\n","quote_model.load_state_dict(model_dict)\n","\n","quote_model = quote_model.to(device)\n","quote_input_ids = quote_input_ids.to(device)\n","\n","quote_embeddings = []\n","quote_model.eval()\n","\n","with torch.no_grad():\n","    for input_ids in quote_input_ids:\n","        input_ids = input_ids.unsqueeze(dim=0)\n","        outputs = quote_model(input_ids=input_ids)\n","        quote_tensor = torch.mean(outputs[0], dim=1)\n","        quote_embeddings.append(quote_tensor)\n","    quote_embeddings = torch.cat(quote_embeddings, dim=0)\n"],"metadata":{"id":"BgODzAlUelT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the mask method for training\n","class QuotRecNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, input_ids, token_type_ids, attention_masks,\n","                mask_ids, quote_tensor):\n","        outputs = self.bert_model(input_ids=input_ids,\n","                                  token_type_ids=token_type_ids,\n","                                  attention_mask=attention_masks)\n","        last_hidden_state = outputs[0]\n","        all_outputs = []\n","        for i in range(len(last_hidden_state)):\n","            mask = last_hidden_state[i][mask_ids[i]]\n","            context = self.dropout(mask)\n","            context = context.unsqueeze(dim=0)\n","            output = torch.mm(context, quote_tensor.t())\n","            all_outputs.append(output)\n","        all_outputs = torch.cat(all_outputs, dim=0)\n","        return all_outputs\n","\n","\n","model = QuotRecNet()\n","model.to(device)\n"],"metadata":{"id":"P82Gpy9MTjVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670735855275,"user_tz":-540,"elapsed":3431,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"d6e52a45-a91b-46f6-9e5c-72989f261741"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["QuotRecNet(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Evaluation Metrics\n","# Rank\n","def rank_gold(predicts, golds):\n","  ranks = []\n","  ps = predicts.data.cpu().numpy()\n","  gs = golds.cpu().numpy()\n","  for i in range(len(ps)):\n","    predict = ps[i]\n","    gold_index = gs[i]\n","    predict_value = predict[gold_index]\n","    predict_sort = sorted(predict, reverse=True)\n","    predict_index = predict_sort.index(predict_value)\n","    if predict_index == -1:\n","        break\n","    ranks.append(predict_index)\n","  return ranks\n","\n","\n","# NDCG@5\n","def get_NDCG(ranks):\n","    total = 0.0\n","    for r in ranks:\n","        if r < 5:  # k=5\n","            total += 1.0 / np.log2(r + 2)\n","    return total / len(ranks)\n","\n","\n","# get recall@k\n","def recall(predicts, golds):\n","    predicts = predicts.data.cpu().numpy()\n","    golds = list(golds)\n","    predicts_index = list(np.argsort(-predicts, axis=1))\n","    predicts_index = [list(element) for element in predicts_index]\n","    recall_values = [0, 0, 0, 0, 0, 0, 0] # 1, 3, 5, 10, 20, 30, 100, 300, 500\n","    recalls = [1, 3, 5, 10, 20, 30, 100]\n","\n","    for i in range(len(golds)):\n","        gold_value_index = predicts_index[i].index(golds[i])\n","        for val in range(len(recalls)):\n","            if gold_value_index < recalls[val]:\n","                recall_values[val] += 1\n","\n","    return recall_values\n","\n","def get_mrr(ranks):\n","    return np.average([1.0 / (r + 1) for r in ranks])"],"metadata":{"id":"4OvvDjTWe0ke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training_mask(model, epoch, train, valid, quote_tensor, device):\n","    learning_rate = 3e-5\n","    len_train = len(train)\n","    len_valid = len(valid)\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    best_MRR = 0\n","    count = 0\n","    quote_tensor = quote_tensor.to(device)\n","    for epoch in range(epoch):\n","        start = time.perf_counter()\n","        print(\"Epoch: \", epoch + 1)\n","        total_loss, total_MRR, total_NDCG = 0, 0, 0\n","        \n","        model.train()\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(train):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","  \n","            ranks = rank_gold(outputs, labels)\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","        end = time.perf_counter()\n","        print('Epoch running time :{:.0f}'.format(end - start))\n","        print('Train | Loss:{:.3f} MRR: {:.3f} NDCG: {:.3f}'.format(total_loss, total_MRR/len_train, total_NDCG/len_train))\n","\n","        # validation\n","        model.eval()\n","        with torch.no_grad():\n","            total_loss, total_MRR, total_NDCG = 0, 0, 0\n","            for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(valid):\n","                input_ids = input_ids.to(device)\n","                token_type_ids = token_type_ids.to(device)\n","                attention_masks = attention_masks.to(device)\n","                mask_ids = mask_ids.to(device, dtype=torch.long)\n","                labels = labels.to(device, dtype=torch.long)\n","                outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","                loss = criterion(outputs, labels)\n","                \n","                ranks = rank_gold(outputs, labels)\n","                MRR = get_mrr(ranks)\n","                NDCG = get_NDCG(ranks)\n","                \n","                total_loss += loss.item()\n","                total_MRR += MRR\n","                total_NDCG += NDCG\n","            print(\"Valid | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f}\".format(total_loss, total_MRR / len_valid,total_NDCG / len_valid))\n","        \n","        if total_MRR > best_MRR:\n","            best_MRR = total_MRR\n","            torch.save(model, \"/content/drive/MyDrive/model/model_modern_chinese.model\")\n","            count = 0\n","        else:\n","            learning_rate = learning_rate * 0.9\n","            count += 1\n","        \n","        # Early Stopping\n","        if count == 3:\n","            break"],"metadata":{"id":"ndwGb997fFVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mask Dataset and DataLoader\n","class Dataset_Mask(Dataset):\n","\n","    def __init__(self, input_ids, token_type_ids, attention_masks, mask_ids,\n","                 y):\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_masks = attention_masks\n","        self.mask_ids = mask_ids\n","        self.label = y\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        if self.label is None:\n","            return self.input_ids[idx], self.token_type_ids[\n","                idx], self.attention_masks[idx], self.mask_ids[idx]\n","        return self.input_ids[idx], self.token_type_ids[\n","            idx], self.attention_masks[idx], self.mask_ids[idx], self.label[\n","                idx]\n","\n","\n","print(\"loading train and valid dataloader ...\")\n","train_dataset_mask = Dataset_Mask(input_ids=train_input_ids,\n","                                  token_type_ids=train_token_type_ids,\n","                                  attention_masks=train_attention_masks,\n","                                  mask_ids=train_mask_ids,\n","                                  y=y[0])\n","train_loader_mask = DataLoader(dataset=train_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","valid_dataset_mask = Dataset_Mask(input_ids=valid_input_ids,\n","                                  token_type_ids=valid_token_type_ids,\n","                                  attention_masks=valid_attention_masks,\n","                                  mask_ids=valid_mask_ids,\n","                                  y=y[1])\n","valid_loader_mask = DataLoader(dataset=valid_dataset_mask,\n","                               batch_size=batch,\n","                               shuffle=True,\n","                               num_workers=2)\n","print(\"start traing......\")\n","training_mask(model=model,\n","              epoch=epochs,\n","              train=train_loader_mask,\n","              valid=valid_loader_mask,\n","              quote_tensor=quote_embeddings,\n","              device=device)"],"metadata":{"id":"EMMwKZXYe5mG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670736410112,"user_tz":-540,"elapsed":521168,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"fb6ba2ce-2060-48c5-f7cd-7fc5c401e983"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading train and valid dataloader ...\n","start traing......\n","Epoch:  1\n","Epoch running time :45\n","Train | Loss:2560.674 MRR: 0.190 NDCG: 0.190\n","Valid | Loss:2703.44501 MRR: 0.201 NDCG: 0.202\n","Epoch:  2\n","Epoch running time :47\n","Train | Loss:1548.675 MRR: 0.471 NDCG: 0.492\n","Valid | Loss:2715.12906 MRR: 0.216 NDCG: 0.214\n","Epoch:  3\n","Epoch running time :46\n","Train | Loss:856.691 MRR: 0.712 NDCG: 0.740\n","Valid | Loss:2659.40586 MRR: 0.246 NDCG: 0.246\n","Epoch:  4\n","Epoch running time :46\n","Train | Loss:498.701 MRR: 0.865 NDCG: 0.885\n","Valid | Loss:2689.67739 MRR: 0.263 NDCG: 0.264\n","Epoch:  5\n","Epoch running time :46\n","Train | Loss:279.755 MRR: 0.944 NDCG: 0.956\n","Valid | Loss:2645.59584 MRR: 0.276 NDCG: 0.276\n","Epoch:  6\n","Epoch running time :46\n","Train | Loss:175.847 MRR: 0.973 NDCG: 0.979\n","Valid | Loss:2645.58032 MRR: 0.289 NDCG: 0.288\n","Epoch:  7\n","Epoch running time :46\n","Train | Loss:128.139 MRR: 0.982 NDCG: 0.986\n","Valid | Loss:2680.98535 MRR: 0.285 NDCG: 0.285\n","Epoch:  8\n","Epoch running time :45\n","Train | Loss:101.357 MRR: 0.988 NDCG: 0.991\n","Valid | Loss:2712.24635 MRR: 0.281 NDCG: 0.281\n","Epoch:  9\n","Epoch running time :45\n","Train | Loss:74.230 MRR: 0.992 NDCG: 0.994\n","Valid | Loss:2721.64820 MRR: 0.282 NDCG: 0.282\n"]}]},{"cell_type":"code","source":["def test(model, test_loader, quote_tensor, device):\n","    model.eval()\n","    t_batch = len(test_loader)\n","    criterion = nn.CrossEntropyLoss()\n","    quote_tensor = quote_tensor.to(device)\n","    with torch.no_grad():\n","        total_loss, total_MRR, total_NDCG, total_ranks = 0, 0, 0, 0\n","        total_recalls = [0, 0, 0, 0, 0, 0, 0]\n","        all_ranks = []\n","        for i, (input_ids, token_type_ids, attention_masks, mask_ids, labels) in enumerate(test_loader):\n","            input_ids = input_ids.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            attention_masks = attention_masks.to(device)\n","            mask_ids = mask_ids.to(device, dtype=torch.long)\n","            labels = labels.to(device, dtype=torch.long)\n","            \n","            outputs = model(input_ids, token_type_ids, attention_masks, mask_ids, quote_tensor)\n","            loss = criterion(outputs, labels)\n","            \n","            ranks = rank_gold(outputs, labels)\n","            all_ranks += ranks\n","            MRR = np.average([1.0 / (r + 1) for r in ranks])\n","            NDCG = get_NDCG(ranks)\n","            recalls = recall(outputs, labels)\n","            \n","            total_loss += loss.item()\n","            total_MRR += MRR\n","            total_NDCG += NDCG\n","            total_ranks += np.sum(ranks)\n","            total_recalls = [x + y for x, y in zip(total_recalls, recalls)]\n","\n","        total_recalls = [element / len(y[2]) for element in total_recalls]\n","\n","        print(\n","            \"Test | Loss:{:.5f} MRR: {:.3f} NDCG: {:.3f} Mean Rank: {:.0f} Median Rank: {:.0f} Variance: {:.0f}\"\n","            .format(total_loss, total_MRR / t_batch,\n","                    total_NDCG / t_batch, np.mean(all_ranks),\n","                    np.median(all_ranks)+1,\n","                    np.std(all_ranks)))\n","        print(\"Recall@[1,3,5,10,20,30,100]: \" + str(total_recalls))\n","        \n","\n","test_input_ids, test_token_type_ids, test_attention_masks, test_mask_ids = make_context_tensors(tests[0], tests[2])\n","test_dataset_mask = Dataset_Mask(input_ids=test_input_ids,\n","                                 token_type_ids=test_token_type_ids,\n","                                 attention_masks=test_attention_masks,\n","                                 mask_ids=test_mask_ids,\n","                                 y=y[2])\n","test_loader_mask = DataLoader(dataset=test_dataset_mask,\n","                              batch_size=batch,\n","                              num_workers=2)\n","\n","model = torch.load('/content/drive/MyDrive/model/model_modern_chinese.model')\n","model.to(device)\n","test(model=model,\n","     test_loader=test_loader_mask,\n","     quote_tensor=quote_embeddings,\n","     device=device)"],"metadata":{"id":"w_WTyan4fBLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670736465940,"user_tz":-540,"elapsed":16851,"user":{"displayName":"BERT Check","userId":"03987380584089583084"}},"outputId":"6a63accc-50d0-4a8c-a6fb-c27ca75c795c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test | Loss:2758.61992 MRR: 0.274 NDCG: 0.278 Mean Rank: 145 Median Rank: 30 Variance: 233\n","Recall@[1,3,5,10,20,30,100]: [0.209, 0.293, 0.339, 0.392, 0.457, 0.505, 0.647]\n"]}]}]}